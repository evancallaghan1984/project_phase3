{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912be84c",
   "metadata": {},
   "source": [
    "# Phase 3: Investment Fund\n",
    "* Student Name: Evan Callaghan\n",
    "* Student Pace: Part Time\n",
    "* Scheduled Project Review Date/Time: \n",
    "* Instructor Name: Mark Barbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00dd182",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "*Callaghan Investments* is a newly formed investment firm specializing in asset allocation and portfolio management. As part of our goal of onboarding the influx of retail investors entering the market at increased rates, we have recently designed, implimented, and got S.E.C approval of our new fleet of Exchange-Traded Funds (ETFs) covering a variety of sectors such as technology, energy, healthcare, financial, real estate, and cryptocurrency (Bitcoin, Ethereum, and Solana). We created these ETFs to provide our clients and investors with a easy way to diversify their portfolio and manage risk in volatile conditions. \n",
    "\n",
    "While many investors are satisfied with the basket of stocks provided in the ETFs, recent market research shows a significant portion of investors want to take on more risk by investing in individual stocks. To meet this demand, Callaghan Investments is going to offer a stock screening service for our higher capital investors. This service will recommend stocks which have a high probability of increasing in price over the medium term (3 months to 1 year). To build this stock screener, we are going to create a machine learning model to predict whether a stock is likely to beat it's next quarterly estimated earnings per share (EPS). This will be based off the stock's valuation parameters and historical earnings data. \n",
    "\n",
    "The reason we are building the model to predict whether a stock will beat its' estimated EPS is because it displays that the company has solid fundamentals, is growing steadily, and will often rise in price after beating its' estimated EPS. An Anderson Review article from UCLA states that positive earnings surprises caused stocks to rise an average of 2.4% in price in the days following the announcement, while companies that did not beat their earnings report dropped an average of 3.5% in price. (https://anderson-review.ucla.edu/when-individuals-concentrate-in-a-stock-earnings-surprises-play-out-differently/). Therefore, building this model is not only good for medium term traders, but also short term traders. This service will provide monthly stock recommendations showing stocks which have the highest probability of beating their earnings report, and therefore having a high likelihood of rising in price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886448b",
   "metadata": {},
   "source": [
    "## The Data\n",
    "The data we are using to creat this predictive model comes from two sources:\n",
    "\n",
    "* nasdaq.com\n",
    "    * Nasdaq.com contains a stock screener with a downloadable CSV file which contains the company name, the stock ticker, and the current marketcap (https://www.nasdaq.com/market-activity/stocks/screener).\n",
    "    * We'll also be using this website to record the companies' previous earnings report, specifically the actual EPS and the predicted EPS. \n",
    "\n",
    "* yfinance\n",
    "    * Yfinance is a library used to access historical data from Yahoo Finance. We use this to find values for the stock valuation parameters we will be using in our analysis, such as P/E Ratio, Return on Equity, and Free Cash Flow.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47313404",
   "metadata": {},
   "source": [
    "## Loading, cleaning, and sorting NASDAQ stock data by market capitalization\n",
    "We'll start by importing our data by loading the downloaded CSV file from the NASDAQ website. We're going to use the top 5,000 stocks by market cap, sorted from highest to lowest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e57160e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Symbol                                               Name Last Sale  \\\n",
      "0      A             Agilent Technologies Inc. Common Stock   $138.31   \n",
      "1     AA                    Alcoa Corporation Common Stock     $34.50   \n",
      "2   AACG   ATA Creativity Global American Depositary Shares   $0.5025   \n",
      "3   AACT  Ares Acquisition Corporation II Class A Ordina...    $10.80   \n",
      "4   AADI                  Aadi Bioscience Inc. Common Stock     $1.88   \n",
      "\n",
      "   Net Change % Change    Market Cap        Country  IPO Year    Volume  \\\n",
      "0      1.0000   0.728%  3.974029e+10  United States    1999.0    887040   \n",
      "1      1.9800   6.089%  8.912735e+09  United States    2016.0  10730428   \n",
      "2     -0.0275  -5.189%  1.608006e+07          China    2008.0     25043   \n",
      "3      0.0200   0.186%  0.000000e+00            NaN    2023.0     35074   \n",
      "4      0.0800   4.444%  4.627589e+07  United States       NaN     81942   \n",
      "\n",
      "        Sector                                          Industry  \n",
      "0  Industrials  Biotechnology: Laboratory Analytical Instruments  \n",
      "1  Industrials                                          Aluminum  \n",
      "2  Real Estate                           Other Consumer Services  \n",
      "3      Finance                                      Blank Checks  \n",
      "4  Health Care        Biotechnology: Pharmaceutical Preparations  \n",
      "     Symbol                                 Name    Market Cap\n",
      "15     AAPL              Apple Inc. Common Stock  3.288959e+12\n",
      "4208   MSFT   Microsoft Corporation Common Stock  3.206167e+12\n",
      "4559   NVDA      NVIDIA Corporation Common Stock  2.864613e+12\n",
      "2819   GOOG  Alphabet Inc. Class C Capital Stock  1.957167e+12\n",
      "2820  GOOGL   Alphabet Inc. Class A Common Stock  1.945719e+12\n"
     ]
    }
   ],
   "source": [
    "# Importing pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = '/Users/evancallaghan/Downloads/nasdaq_screener_1726538993372.csv' \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Inspect the DataFrame to understand its structure\n",
    "print(df.head())\n",
    "\n",
    "# Filter DataFrame to only show the columns 'Symbol', 'Name', and 'Market Cap'\n",
    "df = df[['Symbol', 'Name', 'Market Cap']]\n",
    "\n",
    "# Convert 'Market Cap' to numeric if it's not already\n",
    "# Remove commas, dollar signs, and replace these symbols with empty spaces\n",
    "df['Market Cap'] = df['Market Cap'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Sort the DataFrame by Market Cap in descending order\n",
    "df_sorted = df.sort_values(by='Market Cap', ascending=False).head(5000)                                                                        \n",
    "print(df_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8966a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Alphabet Inc. Class C Capital Stock</td>\n",
       "      <td>1.957167e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                 Name    Market Cap\n",
       "1   AAPL              Apple Inc. Common Stock  3.288959e+12\n",
       "2   MSFT   Microsoft Corporation Common Stock  3.206167e+12\n",
       "3   NVDA      NVIDIA Corporation Common Stock  2.864613e+12\n",
       "4   GOOG  Alphabet Inc. Class C Capital Stock  1.957167e+12\n",
       "5  GOOGL   Alphabet Inc. Class A Common Stock  1.945719e+12"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index of the DataFrame and drop the old index\n",
    "df_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update the index to start from 1 instead of 0\n",
    "df_sorted.index = df_sorted.index + 1\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf20ed5",
   "metadata": {},
   "source": [
    "## Stock Valuation Parameters\n",
    "Below is a list of the stock valuation parameters we will implement into our model. Due to data limitations, some of these values will not be available. If that is the case, we will remove that parameter and continue the analysis with the remaining attributes. \n",
    "\n",
    "1. Price to earnings ratio\n",
    "2. price to book ratio\n",
    "3. dividend yield\n",
    "4. earnings per share\n",
    "5. return on equity\n",
    "6. debt to equity ratio\n",
    "7. free cash flow\n",
    "8. revenue growth\n",
    "9. beta (volatility)\n",
    "10. operating margin\n",
    "11. gross margin\n",
    "12. net profit margin\n",
    "13. price to sales ratio\n",
    "14. current ratio\n",
    "15. quick ratio\n",
    "16. interest coverage ratio\n",
    "17. dividennt payout ratio\n",
    "18. return on assets\n",
    "19. return on investment\n",
    "20. enterprise value\n",
    "21. enterprise value ooon EBITDA\n",
    "22. price to free cash flow rate\n",
    "23. PEG ratio (price/earnings to growth ratio)\n",
    "24. book value per share\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0b969",
   "metadata": {},
   "source": [
    "## Stock Data Cleanup: Remove all except common stock\n",
    "For building this model, it is crucial to only include stocks from our DataFrame that are labeled as 'Common Stock' because it represents ownership in the company and dividend claims. The other types of securities in our Dataframe ('Capital Stock', 'Depository Shares', 'Global Notes', and 'Registry Shares'), have differnet structures, risk profiles, and financial treatments. These can and will distort our model because they do not behave like 'Common Stock' in terms of price, earnings growth, or market reaction to financial reports. By removing these, the model can solely rely on securities that accurately reflect a companies' core earnings performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b21ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap\n",
       "1   AAPL             Apple Inc. Common Stock  3.288959e+12\n",
       "2   MSFT  Microsoft Corporation Common Stock  3.206167e+12\n",
       "3   NVDA     NVIDIA Corporation Common Stock  2.864613e+12\n",
       "5  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12\n",
       "6   AMZN        Amazon.com Inc. Common Stock  1.940525e+12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure there are no leading or trailing whitespaces in the 'Name' column\n",
    "df_sorted['Name'] = df_sorted['Name'].str.strip()\n",
    "\n",
    "# List of terms to filter out\n",
    "terms_to_drop = [\"Capital Stock\", \"Depository Shares\", \"Global Notes\", \"ADS\", \n",
    "                 \"Registry Shares\", \"Depositary Shares\"\n",
    "]\n",
    "\n",
    "# Create a regex pattern to match any of the terms\n",
    "# //b ensures that the match occues only at the start or end of a word\n",
    "# pipe '|' ensures that if any of the terms in 'terms_to_drop' are seen, \n",
    "# there is a match\n",
    "pattern = '|'.join([f\"\\\\b{term}\\\\b\" for term in terms_to_drop])\n",
    "\n",
    "# Apply filtering based on the updated pattern\n",
    "df_filtered = df_sorted[~df_sorted['Name'].str.contains(pattern, case=False, \n",
    "                                                        na=False)\n",
    "]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3880118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap\n",
       "1   AAPL             Apple Inc. Common Stock  3.288959e+12\n",
       "2   MSFT  Microsoft Corporation Common Stock  3.206167e+12\n",
       "3   NVDA     NVIDIA Corporation Common Stock  2.864613e+12\n",
       "4  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12\n",
       "5   AMZN        Amazon.com Inc. Common Stock  1.940525e+12"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index to account for the new filtering\n",
    "df_filtered.reset_index(drop=True, inplace=True)\n",
    "df_filtered.index = df_filtered.index + 1\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afc3be4c-678c-448a-a663-b0649405297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol        4682\n",
       "Name          4682\n",
       "Market Cap    4682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the rows in our new DataFrame to ensure that filtering was done\n",
    "# and to see how many rows we have left\n",
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25aae2a",
   "metadata": {},
   "source": [
    "## Import Stock Valuation Parameters from Yahoo Finance\n",
    "Now we are going to pull financial ratios and valuation parameters for our list of stocks using the yfinance library and organize it into a pandas dataframe. This pull takes a significant amount of time, so in order to save time when running this notebook, I will convert our resulting DataFrame into a CSV file to make it easier to load. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a CSV file of this information provided, as this code is\n",
    "# computationally intensive\n",
    "# Import the yfinance library for fetching financial data\n",
    "#import yfinance as yf\n",
    "\n",
    "# Function to get various financial ratios\n",
    "#def get_financial_data(symbol):\n",
    "#    try:\n",
    "#        stock = yf.Ticker(symbol)\n",
    "#        info = stock.info\n",
    "        \n",
    "        # Define the parameters and their corresponding keys in the info dictionary\n",
    "#        parameters = {\n",
    "#            'Trailing P/E Ratio': 'trailingPE',\n",
    "#            'Forward P/E Ratio': 'forwardPE',\n",
    "#            'Price to Book Ratio': 'priceToBook',\n",
    "#            'Dividend Yield': 'dividendYield',\n",
    "#            'Earnings Per Share Trailing': 'epsTrailingTwelveMonths',\n",
    "#            'Earnings Per Share Forward': 'forwardEps',\n",
    "#            'Return on Equity': 'returnOnEquity',\n",
    "#            'Debt to Equity Ratio': 'debtToEquity',\n",
    "#            'Free Cash Flow': 'freeCashflow',\n",
    "#            'Revenue Growth': 'revenueGrowth',\n",
    "#            'Beta (Volatility)': 'beta',\n",
    "#            'Operating Margin': 'operatingMargins',\n",
    "#            'Gross Margin': 'grossMargins',\n",
    "#            'Net Profit Margin': 'profitMargins',\n",
    "#            'Price to Sales Ratio': 'priceToSalesTrailing12Months',\n",
    "#            'Current Ratio': 'currentRatio',\n",
    "#            'Quick Ratio': 'quickRatio',\n",
    "#            'Interest Coverage Ratio': 'interestCoverageRatio',\n",
    "#            'Dividend Payout Ratio': 'dividendPayoutRatio',\n",
    "#            'Return on Assets': 'returnOnAssets',\n",
    "#            'Return on Investment': 'returnOnInvestment',\n",
    "#            'Enterprise Value': 'enterpriseValue',\n",
    "#            'Enterprise Value to EBITDA': 'enterpriseToEbitda',\n",
    "#            'Price to Free Cash Flow': 'priceToFreeCashflow',\n",
    "#            'PEG Ratio': 'pegRatio',\n",
    "#            'Book Value Per Share': 'bookValue'\n",
    "#        }\n",
    "        \n",
    "        # Extract data\n",
    "#        data = {param: info.get(key, 'Not Available') for param, key in parameters.items()}\n",
    "        \n",
    "#        return data\n",
    "#    except Exception as e:\n",
    "#        return {'Symbol': symbol, 'Error': str(e)}\n",
    "\n",
    "# List of stock symbols\n",
    "#stock_symbols = df_filtered['Symbol'].tolist()\n",
    "\n",
    "# Create lists to store data\n",
    "#all_data = []\n",
    "\n",
    "# Fetch financial data for each stock\n",
    "#for symbol in stock_symbols:\n",
    "#    data = get_financial_data(symbol)\n",
    "#    data['Symbol'] = symbol\n",
    "#    all_data.append(data)\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "#df_financial_data = pd.DataFrame(all_data)\n",
    "\n",
    "# Reset the index to start at 1 for readability\n",
    "#df_financial_data.index = df_financial_data.index + 1\n",
    "\n",
    "# Display the DataFrame\n",
    "#df_financial_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184ba15-38fd-49c2-a9f0-0b1967557a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file for later use\n",
    "#df_financial_data.to_csv('df_financial_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a90c4ba9-b3db-40d6-b52c-c6a43f1b4860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Trailing</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>Free Cash Flow</th>\n",
       "      <th>Revenue Growth</th>\n",
       "      <th>...</th>\n",
       "      <th>Dividend Payout Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Return on Investment</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>Price to Free Cash Flow</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.58402</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.5741299</td>\n",
       "      <td>209.059</td>\n",
       "      <td>110846001152</td>\n",
       "      <td>0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3456762118144</td>\n",
       "      <td>25.67</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.767</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.22195</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>61280874496</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3179720212480</td>\n",
       "      <td>23.286</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>38.693</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.57943</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.97635</td>\n",
       "      <td>0.00029999999</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>33725874176</td>\n",
       "      <td>1.224</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3563218010112</td>\n",
       "      <td>58.238</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>2.368</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.8551126</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101002</td>\n",
       "      <td>9.324</td>\n",
       "      <td>41104498688</td>\n",
       "      <td>0.151</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>2125729103872</td>\n",
       "      <td>17.217</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>25.613</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.41178</td>\n",
       "      <td>8.57757</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>54328250368</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>2321747804160</td>\n",
       "      <td>20.807</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>24.655</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trailing P/E Ratio Forward P/E Ratio Price to Book Ratio Dividend Yield  \\\n",
       "0          37.536186         27.493536            60.58402         0.0044   \n",
       "1           35.22195         28.298223           11.032745         0.0078   \n",
       "2           68.57943         35.295135            61.97635  0.00029999999   \n",
       "3          23.255629         19.583218           6.8551126         0.0045   \n",
       "4          45.091682          34.41178             8.57757  Not Available   \n",
       "\n",
       "  Earnings Per Share Trailing Earnings Per Share Forward Return on Equity  \\\n",
       "0               Not Available                       8.31        1.5741299   \n",
       "1               Not Available                      14.95          0.35604   \n",
       "2               Not Available                       4.12          1.23767   \n",
       "3               Not Available                       8.96       0.32101002   \n",
       "4               Not Available                       6.15          0.22558   \n",
       "\n",
       "  Debt to Equity Ratio Free Cash Flow Revenue Growth  ...  \\\n",
       "0              209.059   110846001152          0.061  ...   \n",
       "1               33.657    61280874496           0.16  ...   \n",
       "2               17.221    33725874176          1.224  ...   \n",
       "3                9.324    41104498688          0.151  ...   \n",
       "4               61.175    54328250368           0.11  ...   \n",
       "\n",
       "  Dividend Payout Ratio Return on Assets Return on Investment  \\\n",
       "0         Not Available          0.21464        Not Available   \n",
       "1         Not Available          0.14592        Not Available   \n",
       "2         Not Available          0.55258        Not Available   \n",
       "3         Not Available          0.16483        Not Available   \n",
       "4         Not Available          0.07069        Not Available   \n",
       "\n",
       "  Enterprise Value Enterprise Value to EBITDA Price to Free Cash Flow  \\\n",
       "0    3456762118144                      25.67           Not Available   \n",
       "1    3179720212480                     23.286           Not Available   \n",
       "2    3563218010112                     58.238           Not Available   \n",
       "3    2125729103872                     17.217           Not Available   \n",
       "4    2321747804160                     20.807           Not Available   \n",
       "\n",
       "       PEG Ratio Book Value Per Share Symbol Error  \n",
       "0  Not Available                3.767   AAPL   NaN  \n",
       "1  Not Available               38.693   MSFT   NaN  \n",
       "2  Not Available                2.368   NVDA   NaN  \n",
       "3  Not Available               25.613  GOOGL   NaN  \n",
       "4  Not Available               24.655   AMZN   NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the CSV file from our files and convert it into a DataFrame\n",
    "df_financial_data = pd.read_csv('data/df_financial_data.csv')\n",
    "df_financial_data.head()\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93088b",
   "metadata": {},
   "source": [
    "## Drop Unavailable Columns\n",
    "Some of the stock valuation parameters we imported are not availble. This could be because the specific company is not obligated to report that information, yahoo finance does not have that particular information, or payment is required to pull that data. Since this data is not available, we're going to drop these columns since they can't be included in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f739219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>Free Cash Flow</th>\n",
       "      <th>Revenue Growth</th>\n",
       "      <th>Beta (Volatility)</th>\n",
       "      <th>...</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.58402</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.5741299</td>\n",
       "      <td>209.059</td>\n",
       "      <td>110846001152</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3456762118144</td>\n",
       "      <td>25.67</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.767</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.22195</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>61280874496</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69348997</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3179720212480</td>\n",
       "      <td>23.286</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>38.693</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.57943</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.97635</td>\n",
       "      <td>0.00029999999</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>33725874176</td>\n",
       "      <td>1.224</td>\n",
       "      <td>1.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75975996</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3563218010112</td>\n",
       "      <td>58.238</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>2.368</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.8551126</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101002</td>\n",
       "      <td>9.324</td>\n",
       "      <td>41104498688</td>\n",
       "      <td>0.151</td>\n",
       "      <td>1.034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2125729103872</td>\n",
       "      <td>17.217</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>25.613</td>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.41178</td>\n",
       "      <td>8.57757</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>54328250368</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.5858924</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2321747804160</td>\n",
       "      <td>20.807</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>24.655</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trailing P/E Ratio Forward P/E Ratio Price to Book Ratio Dividend Yield  \\\n",
       "0          37.536186         27.493536            60.58402         0.0044   \n",
       "1           35.22195         28.298223           11.032745         0.0078   \n",
       "2           68.57943         35.295135            61.97635  0.00029999999   \n",
       "3          23.255629         19.583218           6.8551126         0.0045   \n",
       "4          45.091682          34.41178             8.57757  Not Available   \n",
       "\n",
       "  Earnings Per Share Forward Return on Equity Debt to Equity Ratio  \\\n",
       "0                       8.31        1.5741299              209.059   \n",
       "1                      14.95          0.35604               33.657   \n",
       "2                       4.12          1.23767               17.221   \n",
       "3                       8.96       0.32101002                9.324   \n",
       "4                       6.15          0.22558               61.175   \n",
       "\n",
       "  Free Cash Flow Revenue Growth Beta (Volatility)  ... Gross Margin  \\\n",
       "0   110846001152          0.061              1.24  ...      0.46206   \n",
       "1    61280874496           0.16             0.904  ...   0.69348997   \n",
       "2    33725874176          1.224             1.657  ...   0.75975996   \n",
       "3    41104498688          0.151             1.034  ...      0.58127   \n",
       "4    54328250368           0.11             1.146  ...      0.48406   \n",
       "\n",
       "  Price to Sales Ratio Current Ratio Quick Ratio Return on Assets  \\\n",
       "0             8.822043         0.867       0.745          0.21464   \n",
       "1            12.486235         1.301       1.163          0.14592   \n",
       "2            37.380695         4.269       3.503          0.55258   \n",
       "3             6.349746          1.95       1.761          0.16483   \n",
       "4            3.5858924         1.089       0.827          0.07069   \n",
       "\n",
       "  Enterprise Value Enterprise Value to EBITDA      PEG Ratio  \\\n",
       "0    3456762118144                      25.67  Not Available   \n",
       "1    3179720212480                     23.286  Not Available   \n",
       "2    3563218010112                     58.238  Not Available   \n",
       "3    2125729103872                     17.217  Not Available   \n",
       "4    2321747804160                     20.807  Not Available   \n",
       "\n",
       "  Book Value Per Share Symbol  \n",
       "0                3.767   AAPL  \n",
       "1               38.693   MSFT  \n",
       "2                2.368   NVDA  \n",
       "3               25.613  GOOGL  \n",
       "4               24.655   AMZN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any columns that appear to have 'Not Available' \n",
    "# or 'NaN' values for the majority of the stocks\n",
    "df_financial_data = df_financial_data.drop(columns = [\"Price to Free Cash Flow\", \n",
    "                                                      \"Return on Investment\", \n",
    "                                                      \"Dividend Payout Ratio\", \n",
    "                                                      \"Interest Coverage Ratio\", \n",
    "                                                      \"Net Profit Margin\", \n",
    "                                                      \"Earnings Per Share Trailing\", \n",
    "                                                      \"Error\"], axis=1)\n",
    "df_financial_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4c3df",
   "metadata": {},
   "source": [
    "## Merge DataFrames\n",
    "Now that we have the 'df_financial_data' DataFrame containing valuation parameters associated with each 'Symbol' (stock ticker), we're going to merge it with the 'df_filtered' so that we have one DataFrame containing the financial parameters, 'Symbol', 'Name', and 'Market Cap'. We use 'pd.merge()' to create a new DataFrame called 'df_stocks_data' and merge it based on 'Symbol'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9c3ae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.58402</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.5741299</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3456762118144</td>\n",
       "      <td>25.67</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.22195</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46583998</td>\n",
       "      <td>0.69348997</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3179720212480</td>\n",
       "      <td>23.286</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>38.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.57943</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.97635</td>\n",
       "      <td>0.00029999999</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62057</td>\n",
       "      <td>0.75975996</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3563218010112</td>\n",
       "      <td>58.238</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.8551126</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101002</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32312</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2125729103872</td>\n",
       "      <td>17.217</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>25.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.41178</td>\n",
       "      <td>8.57757</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109589994</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.5858924</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2321747804160</td>\n",
       "      <td>20.807</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>24.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap Trailing P/E Ratio  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12          37.536186   \n",
       "1   MSFT  Microsoft Corporation Common Stock  3.206167e+12           35.22195   \n",
       "2   NVDA     NVIDIA Corporation Common Stock  2.864613e+12           68.57943   \n",
       "3  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12          23.255629   \n",
       "4   AMZN        Amazon.com Inc. Common Stock  1.940525e+12          45.091682   \n",
       "\n",
       "  Forward P/E Ratio Price to Book Ratio Dividend Yield  \\\n",
       "0         27.493536            60.58402         0.0044   \n",
       "1         28.298223           11.032745         0.0078   \n",
       "2         35.295135            61.97635  0.00029999999   \n",
       "3         19.583218           6.8551126         0.0045   \n",
       "4          34.41178             8.57757  Not Available   \n",
       "\n",
       "  Earnings Per Share Forward Return on Equity Debt to Equity Ratio  ...  \\\n",
       "0                       8.31        1.5741299              209.059  ...   \n",
       "1                      14.95          0.35604               33.657  ...   \n",
       "2                       4.12          1.23767               17.221  ...   \n",
       "3                       8.96       0.32101002                9.324  ...   \n",
       "4                       6.15          0.22558               61.175  ...   \n",
       "\n",
       "  Operating Margin Gross Margin Price to Sales Ratio Current Ratio  \\\n",
       "0          0.31171      0.46206             8.822043         0.867   \n",
       "1       0.46583998   0.69348997            12.486235         1.301   \n",
       "2          0.62057   0.75975996            37.380695         4.269   \n",
       "3          0.32312      0.58127             6.349746          1.95   \n",
       "4      0.109589994      0.48406            3.5858924         1.089   \n",
       "\n",
       "  Quick Ratio Return on Assets Enterprise Value Enterprise Value to EBITDA  \\\n",
       "0       0.745          0.21464    3456762118144                      25.67   \n",
       "1       1.163          0.14592    3179720212480                     23.286   \n",
       "2       3.503          0.55258    3563218010112                     58.238   \n",
       "3       1.761          0.16483    2125729103872                     17.217   \n",
       "4       0.827          0.07069    2321747804160                     20.807   \n",
       "\n",
       "       PEG Ratio Book Value Per Share  \n",
       "0  Not Available                3.767  \n",
       "1  Not Available               38.693  \n",
       "2  Not Available                2.368  \n",
       "3  Not Available               25.613  \n",
       "4  Not Available               24.655  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames based on shared column 'Symbol'\n",
    "df_filtered_stocks_data = pd.merge(df_filtered, df_financial_data, on=\"Symbol\")\n",
    "df_filtered_stocks_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf6a8e",
   "metadata": {},
   "source": [
    "## Remove Rows with Insufficient Data\n",
    "Looking at our DataFrame, we can see that some of our stocks have a lot of valuation parameters that are not available. Before performing any kind of imputation, we're going to remove rows which have half or more of the valuation parameters unavailable. This is to prevent us from having too many inaccurate data points that are just median values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34b306c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 4682\n",
      "Number of rows after filtering: 3555\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Not Available' with pd.NA to easily filter the data\n",
    "df_filtered_stocks_data.replace('Not Available', pd.NA, inplace=True)\n",
    "\n",
    "# Put all valuation columns into a variable, dropping the descriptive 'Name' \n",
    "# and 'Symbol' columns\n",
    "valuation_columns = df_filtered_stocks_data.drop(['Name', 'Symbol'], axis=1).columns\n",
    "\n",
    "# Remove rows which have 11 or more missing values in the valuation columns\n",
    "df_filtered_stocks_data = df_filtered_stocks_data[\n",
    "    df_filtered_stocks_data[valuation_columns]\n",
    "    .isna().sum(axis=1) < 11]\n",
    "\n",
    "# Print the original number of rows and the newly filtered rows\n",
    "print(f\"Original number of rows: {len(df_financial_data)}\")\n",
    "\n",
    "print(f\"Number of rows after filtering: {len(df_filtered_stocks_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2692050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.58402</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.5741299</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3456762118144</td>\n",
       "      <td>25.67</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.22195</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46583998</td>\n",
       "      <td>0.69348997</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3179720212480</td>\n",
       "      <td>23.286</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>38.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.57943</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.97635</td>\n",
       "      <td>0.00029999999</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62057</td>\n",
       "      <td>0.75975996</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3563218010112</td>\n",
       "      <td>58.238</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.8551126</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101002</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32312</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2125729103872</td>\n",
       "      <td>17.217</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>25.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.41178</td>\n",
       "      <td>8.57757</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109589994</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.5858924</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2321747804160</td>\n",
       "      <td>20.807</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>24.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap Trailing P/E Ratio  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12          37.536186   \n",
       "1   MSFT  Microsoft Corporation Common Stock  3.206167e+12           35.22195   \n",
       "2   NVDA     NVIDIA Corporation Common Stock  2.864613e+12           68.57943   \n",
       "3  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12          23.255629   \n",
       "4   AMZN        Amazon.com Inc. Common Stock  1.940525e+12          45.091682   \n",
       "\n",
       "  Forward P/E Ratio Price to Book Ratio Dividend Yield  \\\n",
       "0         27.493536            60.58402         0.0044   \n",
       "1         28.298223           11.032745         0.0078   \n",
       "2         35.295135            61.97635  0.00029999999   \n",
       "3         19.583218           6.8551126         0.0045   \n",
       "4          34.41178             8.57757           <NA>   \n",
       "\n",
       "  Earnings Per Share Forward Return on Equity Debt to Equity Ratio  ...  \\\n",
       "0                       8.31        1.5741299              209.059  ...   \n",
       "1                      14.95          0.35604               33.657  ...   \n",
       "2                       4.12          1.23767               17.221  ...   \n",
       "3                       8.96       0.32101002                9.324  ...   \n",
       "4                       6.15          0.22558               61.175  ...   \n",
       "\n",
       "  Operating Margin Gross Margin Price to Sales Ratio Current Ratio  \\\n",
       "0          0.31171      0.46206             8.822043         0.867   \n",
       "1       0.46583998   0.69348997            12.486235         1.301   \n",
       "2          0.62057   0.75975996            37.380695         4.269   \n",
       "3          0.32312      0.58127             6.349746          1.95   \n",
       "4      0.109589994      0.48406            3.5858924         1.089   \n",
       "\n",
       "  Quick Ratio Return on Assets Enterprise Value Enterprise Value to EBITDA  \\\n",
       "0       0.745          0.21464    3456762118144                      25.67   \n",
       "1       1.163          0.14592    3179720212480                     23.286   \n",
       "2       3.503          0.55258    3563218010112                     58.238   \n",
       "3       1.761          0.16483    2125729103872                     17.217   \n",
       "4       0.827          0.07069    2321747804160                     20.807   \n",
       "\n",
       "  PEG Ratio Book Value Per Share  \n",
       "0      <NA>                3.767  \n",
       "1      <NA>               38.693  \n",
       "2      <NA>                2.368  \n",
       "3      <NA>               25.613  \n",
       "4      <NA>               24.655  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_stocks_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662b396",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Median and Constant Value Imputation\n",
    "Now that we have filterd out stocks with too much unavailable data, we are going to use imputation to fill in the rest of the unavailable values, as we need a number there in order to run numerical calculations on it. To avoid outliers and keep the dispersion of data as close as possible to what it is now, we're going to replace all unavailable values with the median value of the column, with the exception being the 'Dividend Yield' column. In this column, we will replace all 'Not Available' with '0.00', as explained below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205a964",
   "metadata": {},
   "source": [
    "## Constant Value Imputation\n",
    "Looking at the 'Dividend Yield' column, some of the rows contain \"Not Available\" values. Since Dividend Yield is calculated as 'Annual Dividend Per Share / Current Stock Price', we're going to assume that any companies with a \"Not Available\" value in their \"Dividend Yield\" column does not give out a dividend. This means that the Dividend Yield for these companies is '0.00'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be2b0f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.58402</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.5741299</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3456762118144</td>\n",
       "      <td>25.67</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.22195</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46583998</td>\n",
       "      <td>0.69348997</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3179720212480</td>\n",
       "      <td>23.286</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>38.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.57943</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.97635</td>\n",
       "      <td>0.00029999999</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62057</td>\n",
       "      <td>0.75975996</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3563218010112</td>\n",
       "      <td>58.238</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.8551126</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101002</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32312</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2125729103872</td>\n",
       "      <td>17.217</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>25.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.41178</td>\n",
       "      <td>8.57757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109589994</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.5858924</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2321747804160</td>\n",
       "      <td>20.807</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>24.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc. Class A Common Stock</td>\n",
       "      <td>1.349101e+12</td>\n",
       "      <td>27.263107</td>\n",
       "      <td>22.794006</td>\n",
       "      <td>8.854049</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.36134</td>\n",
       "      <td>29.811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42765</td>\n",
       "      <td>0.81501</td>\n",
       "      <td>9.326395</td>\n",
       "      <td>2.732</td>\n",
       "      <td>2.568</td>\n",
       "      <td>0.17188999</td>\n",
       "      <td>1442350366720</td>\n",
       "      <td>18.209</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>65.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company Common Stock</td>\n",
       "      <td>8.777562e+11</td>\n",
       "      <td>84.99783</td>\n",
       "      <td>34.744507</td>\n",
       "      <td>49.68278</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>22.66</td>\n",
       "      <td>0.65318</td>\n",
       "      <td>218.081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39773998</td>\n",
       "      <td>0.80906</td>\n",
       "      <td>18.265305</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.13946</td>\n",
       "      <td>757866496000</td>\n",
       "      <td>45.747</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>15.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufacturing Company Ltd.</td>\n",
       "      <td>8.769189e+11</td>\n",
       "      <td>33.902878</td>\n",
       "      <td>21.246187</td>\n",
       "      <td>1.2249168</td>\n",
       "      <td>0.013200001</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.28027</td>\n",
       "      <td>24.081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47487998</td>\n",
       "      <td>0.54453</td>\n",
       "      <td>0.36870518</td>\n",
       "      <td>2.567</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.12409</td>\n",
       "      <td>3672532582400</td>\n",
       "      <td>2.043</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>153.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>Broadcom Inc. Common Stock</td>\n",
       "      <td>7.660679e+11</td>\n",
       "      <td>138.52032</td>\n",
       "      <td>27.499495</td>\n",
       "      <td>2.8770201</td>\n",
       "      <td>0.012200001</td>\n",
       "      <td>6.17</td>\n",
       "      <td>0.12509</td>\n",
       "      <td>166.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31765</td>\n",
       "      <td>0.74713</td>\n",
       "      <td>16.99826</td>\n",
       "      <td>1.038</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.077010006</td>\n",
       "      <td>100720377856</td>\n",
       "      <td>4.387</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>59.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla Inc. Common Stock</td>\n",
       "      <td>7.244806e+11</td>\n",
       "      <td>84.790184</td>\n",
       "      <td>95.36681</td>\n",
       "      <td>14.270384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.20389</td>\n",
       "      <td>18.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107889995</td>\n",
       "      <td>0.18229</td>\n",
       "      <td>10.2821045</td>\n",
       "      <td>1.844</td>\n",
       "      <td>1.214</td>\n",
       "      <td>0.04759</td>\n",
       "      <td>1040004087808</td>\n",
       "      <td>78.526</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WMT</td>\n",
       "      <td>Walmart Inc. Common Stock</td>\n",
       "      <td>6.475615e+11</td>\n",
       "      <td>43.994793</td>\n",
       "      <td>31.026402</td>\n",
       "      <td>8.039402</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.18531999</td>\n",
       "      <td>69.566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04689</td>\n",
       "      <td>0.24628</td>\n",
       "      <td>1.0209852</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.069510005</td>\n",
       "      <td>747954503680</td>\n",
       "      <td>18.342</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NVO</td>\n",
       "      <td>Novo Nordisk A/S Common Stock</td>\n",
       "      <td>6.108792e+11</td>\n",
       "      <td>34.990032</td>\n",
       "      <td>3.7756453</td>\n",
       "      <td>3.8906538</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.88725996</td>\n",
       "      <td>47.271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47429</td>\n",
       "      <td>0.84657997</td>\n",
       "      <td>1.7316614</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.21465999</td>\n",
       "      <td>458086383616</td>\n",
       "      <td>3.596</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>27.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JPM</td>\n",
       "      <td>JP Morgan Chase &amp; Co. Common Stock</td>\n",
       "      <td>5.913959e+11</td>\n",
       "      <td>13.444692</td>\n",
       "      <td>14.349644</td>\n",
       "      <td>2.1004775</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>16.74</td>\n",
       "      <td>0.16216</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43787998</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.1995354</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.013259999</td>\n",
       "      <td>205751500800</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>115.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UNH</td>\n",
       "      <td>UnitedHealth Group Incorporated Common Stock (DE)</td>\n",
       "      <td>5.440226e+11</td>\n",
       "      <td>38.54126</td>\n",
       "      <td>19.725695</td>\n",
       "      <td>5.791293</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.15252</td>\n",
       "      <td>74.683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08637</td>\n",
       "      <td>0.22872</td>\n",
       "      <td>1.3858067</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>608368656384</td>\n",
       "      <td>17.365</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>102.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V</td>\n",
       "      <td>Visa Inc.</td>\n",
       "      <td>5.293435e+11</td>\n",
       "      <td>31.712961</td>\n",
       "      <td>24.373024</td>\n",
       "      <td>15.35339</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>12.66</td>\n",
       "      <td>0.50708</td>\n",
       "      <td>53.239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66122</td>\n",
       "      <td>0.97833997</td>\n",
       "      <td>16.617924</td>\n",
       "      <td>1.283</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.16174</td>\n",
       "      <td>584800665600</td>\n",
       "      <td>23.417</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corporation Common Stock</td>\n",
       "      <td>5.007510e+11</td>\n",
       "      <td>15.013699</td>\n",
       "      <td>14.677951</td>\n",
       "      <td>1.9727713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.14513999</td>\n",
       "      <td>15.394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13274</td>\n",
       "      <td>0.31535</td>\n",
       "      <td>1.541141</td>\n",
       "      <td>1.348</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.07083</td>\n",
       "      <td>557304119296</td>\n",
       "      <td>7.79</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>61.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle Corporation Common Stock</td>\n",
       "      <td>4.719790e+11</td>\n",
       "      <td>48.08483</td>\n",
       "      <td>26.148077</td>\n",
       "      <td>47.92467</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>7.16</td>\n",
       "      <td>1.55578</td>\n",
       "      <td>749.978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30517998</td>\n",
       "      <td>0.71310997</td>\n",
       "      <td>9.631641</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.072909996</td>\n",
       "      <td>599515660288</td>\n",
       "      <td>27.497</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MA</td>\n",
       "      <td>Mastercard Incorporated Common Stock</td>\n",
       "      <td>4.598019e+11</td>\n",
       "      <td>39.245853</td>\n",
       "      <td>31.758354</td>\n",
       "      <td>64.3502</td>\n",
       "      <td>0.0050999997</td>\n",
       "      <td>16.38</td>\n",
       "      <td>1.7757801</td>\n",
       "      <td>244.839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59301996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.543499</td>\n",
       "      <td>1.289</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.22886999</td>\n",
       "      <td>486012649472</td>\n",
       "      <td>28.957</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PG</td>\n",
       "      <td>Procter &amp; Gamble Company (The) Common Stock</td>\n",
       "      <td>4.172320e+11</td>\n",
       "      <td>28.806896</td>\n",
       "      <td>22.54444</td>\n",
       "      <td>7.708064</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>7.42</td>\n",
       "      <td>0.28766</td>\n",
       "      <td>69.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27763999</td>\n",
       "      <td>0.51756</td>\n",
       "      <td>4.68959</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.10601</td>\n",
       "      <td>417390854144</td>\n",
       "      <td>17.362</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>COST</td>\n",
       "      <td>Costco Wholesale Corporation Common Stock</td>\n",
       "      <td>4.024906e+11</td>\n",
       "      <td>55.891712</td>\n",
       "      <td>47.140396</td>\n",
       "      <td>17.331171</td>\n",
       "      <td>0.005</td>\n",
       "      <td>19.68</td>\n",
       "      <td>0.30267</td>\n",
       "      <td>42.118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03817</td>\n",
       "      <td>0.12613</td>\n",
       "      <td>1.6087513</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>412516057088</td>\n",
       "      <td>35.802</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>53.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>Johnson &amp; Johnson Common Stock</td>\n",
       "      <td>4.019856e+11</td>\n",
       "      <td>25.102478</td>\n",
       "      <td>14.283859</td>\n",
       "      <td>5.211021</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.20889</td>\n",
       "      <td>50.958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24516001</td>\n",
       "      <td>0.69391</td>\n",
       "      <td>4.1694636</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.08403</td>\n",
       "      <td>384398131200</td>\n",
       "      <td>12.791</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>29.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HD</td>\n",
       "      <td>Home Depot Inc. (The) Common Stock</td>\n",
       "      <td>3.794480e+11</td>\n",
       "      <td>27.247816</td>\n",
       "      <td>25.767067</td>\n",
       "      <td>69.4845</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.04933</td>\n",
       "      <td>1095.368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13472</td>\n",
       "      <td>0.33495</td>\n",
       "      <td>2.606787</td>\n",
       "      <td>1.133</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.15313</td>\n",
       "      <td>468345290752</td>\n",
       "      <td>18.917</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc. Common Stock</td>\n",
       "      <td>3.457265e+11</td>\n",
       "      <td>59.31119</td>\n",
       "      <td>14.009017</td>\n",
       "      <td>49.70114</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.56407</td>\n",
       "      <td>1174.815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28928</td>\n",
       "      <td>0.70335</td>\n",
       "      <td>5.397871</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.077199996</td>\n",
       "      <td>365109346304</td>\n",
       "      <td>14.245</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KO</td>\n",
       "      <td>Coca-Cola Company (The) Common Stock</td>\n",
       "      <td>3.107415e+11</td>\n",
       "      <td>25.954355</td>\n",
       "      <td>20.861404</td>\n",
       "      <td>10.165772</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.3723</td>\n",
       "      <td>167.358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30235</td>\n",
       "      <td>0.60433996</td>\n",
       "      <td>5.811433</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.08438</td>\n",
       "      <td>301981204480</td>\n",
       "      <td>20.361</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>6.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BAC</td>\n",
       "      <td>Bank of America Corporation Common Stock</td>\n",
       "      <td>3.033995e+11</td>\n",
       "      <td>16.630436</td>\n",
       "      <td>12.536874</td>\n",
       "      <td>1.2976733</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.08092</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30769</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.7218654</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0072899996</td>\n",
       "      <td>348427976704</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>35.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                                               Name    Market Cap  \\\n",
       "0    AAPL                            Apple Inc. Common Stock  3.288959e+12   \n",
       "1    MSFT                 Microsoft Corporation Common Stock  3.206167e+12   \n",
       "2    NVDA                    NVIDIA Corporation Common Stock  2.864613e+12   \n",
       "3   GOOGL                 Alphabet Inc. Class A Common Stock  1.945719e+12   \n",
       "4    AMZN                       Amazon.com Inc. Common Stock  1.940525e+12   \n",
       "5    META           Meta Platforms Inc. Class A Common Stock  1.349101e+12   \n",
       "8     LLY                 Eli Lilly and Company Common Stock  8.777562e+11   \n",
       "9     TSM    Taiwan Semiconductor Manufacturing Company Ltd.  8.769189e+11   \n",
       "10   AVGO                         Broadcom Inc. Common Stock  7.660679e+11   \n",
       "11   TSLA                            Tesla Inc. Common Stock  7.244806e+11   \n",
       "12    WMT                          Walmart Inc. Common Stock  6.475615e+11   \n",
       "13    NVO                      Novo Nordisk A/S Common Stock  6.108792e+11   \n",
       "14    JPM                 JP Morgan Chase & Co. Common Stock  5.913959e+11   \n",
       "15    UNH  UnitedHealth Group Incorporated Common Stock (DE)  5.440226e+11   \n",
       "16      V                                          Visa Inc.  5.293435e+11   \n",
       "17    XOM               Exxon Mobil Corporation Common Stock  5.007510e+11   \n",
       "18   ORCL                    Oracle Corporation Common Stock  4.719790e+11   \n",
       "19     MA               Mastercard Incorporated Common Stock  4.598019e+11   \n",
       "20     PG        Procter & Gamble Company (The) Common Stock  4.172320e+11   \n",
       "21   COST          Costco Wholesale Corporation Common Stock  4.024906e+11   \n",
       "22    JNJ                     Johnson & Johnson Common Stock  4.019856e+11   \n",
       "23     HD                 Home Depot Inc. (The) Common Stock  3.794480e+11   \n",
       "24   ABBV                           AbbVie Inc. Common Stock  3.457265e+11   \n",
       "25     KO               Coca-Cola Company (The) Common Stock  3.107415e+11   \n",
       "26    BAC           Bank of America Corporation Common Stock  3.033995e+11   \n",
       "\n",
       "   Trailing P/E Ratio Forward P/E Ratio Price to Book Ratio Dividend Yield  \\\n",
       "0           37.536186         27.493536            60.58402         0.0044   \n",
       "1            35.22195         28.298223           11.032745         0.0078   \n",
       "2            68.57943         35.295135            61.97635  0.00029999999   \n",
       "3           23.255629         19.583218           6.8551126         0.0045   \n",
       "4           45.091682          34.41178             8.57757            0.0   \n",
       "5           27.263107         22.794006            8.854049         0.0034   \n",
       "8            84.99783         34.744507            49.68278         0.0064   \n",
       "9           33.902878         21.246187           1.2249168    0.013200001   \n",
       "10          138.52032         27.499495           2.8770201    0.012200001   \n",
       "11          84.790184          95.36681           14.270384            0.0   \n",
       "12          43.994793         31.026402            8.039402         0.0097   \n",
       "13          34.990032         3.7756453           3.8906538         0.0135   \n",
       "14          13.444692         14.349644           2.1004775         0.0207   \n",
       "15           38.54126         19.725695            5.791293         0.0139   \n",
       "16          31.712961         24.373024            15.35339         0.0076   \n",
       "17          15.013699         14.677951           1.9727713         0.0326   \n",
       "18           48.08483         26.148077            47.92467         0.0084   \n",
       "19          39.245853         31.758354             64.3502   0.0050999997   \n",
       "20          28.806896          22.54444            7.708064         0.0242   \n",
       "21          55.891712         47.140396           17.331171          0.005   \n",
       "22          25.102478         14.283859            5.211021         0.0324   \n",
       "23          27.247816         25.767067             69.4845         0.0219   \n",
       "24           59.31119         14.009017            49.70114         0.0385   \n",
       "25          25.954355         20.861404           10.165772         0.0308   \n",
       "26          16.630436         12.536874           1.2976733         0.0227   \n",
       "\n",
       "   Earnings Per Share Forward Return on Equity Debt to Equity Ratio  ...  \\\n",
       "0                        8.31        1.5741299              209.059  ...   \n",
       "1                       14.95          0.35604               33.657  ...   \n",
       "2                        4.12          1.23767               17.221  ...   \n",
       "3                        8.96       0.32101002                9.324  ...   \n",
       "4                        6.15          0.22558               61.175  ...   \n",
       "5                        25.3          0.36134               29.811  ...   \n",
       "8                       22.66          0.65318              218.081  ...   \n",
       "9                        8.08          0.28027               24.081  ...   \n",
       "10                       6.17          0.12509              166.032  ...   \n",
       "11                       3.24          0.20389               18.078  ...   \n",
       "12                       2.72       0.18531999               69.566  ...   \n",
       "13                       4.07       0.88725996               47.271  ...   \n",
       "14                      16.74          0.16216                 <NA>  ...   \n",
       "15                       29.9          0.15252               74.683  ...   \n",
       "16                      12.66          0.50708               53.239  ...   \n",
       "17                       7.87       0.14513999               15.394  ...   \n",
       "18                       7.16          1.55578              749.978  ...   \n",
       "19                      16.38        1.7757801              244.839  ...   \n",
       "20                       7.42          0.28766               69.338  ...   \n",
       "21                      19.68          0.30267               42.118  ...   \n",
       "22                       10.6          0.20889               50.958  ...   \n",
       "23                       15.6          4.04933             1095.368  ...   \n",
       "24                      12.13          0.56407             1174.815  ...   \n",
       "25                       2.97           0.3723              167.358  ...   \n",
       "26                       3.66          0.08092                 <NA>  ...   \n",
       "\n",
       "   Operating Margin Gross Margin Price to Sales Ratio Current Ratio  \\\n",
       "0           0.31171      0.46206             8.822043         0.867   \n",
       "1        0.46583998   0.69348997            12.486235         1.301   \n",
       "2           0.62057   0.75975996            37.380695         4.269   \n",
       "3           0.32312      0.58127             6.349746          1.95   \n",
       "4       0.109589994      0.48406            3.5858924         1.089   \n",
       "5           0.42765      0.81501             9.326395         2.732   \n",
       "8        0.39773998      0.80906            18.265305         1.273   \n",
       "9        0.47487998      0.54453           0.36870518         2.567   \n",
       "10          0.31765      0.74713             16.99826         1.038   \n",
       "11      0.107889995      0.18229           10.2821045         1.844   \n",
       "12          0.04689      0.24628            1.0209852         0.803   \n",
       "13          0.47429   0.84657997            1.7316614         0.937   \n",
       "14       0.43787998         <NA>            4.1995354          <NA>   \n",
       "15          0.08637      0.22872            1.3858067         0.908   \n",
       "16          0.66122   0.97833997            16.617924         1.283   \n",
       "17          0.13274      0.31535             1.541141         1.348   \n",
       "18       0.30517998   0.71310997             9.631641          0.72   \n",
       "19       0.59301996          1.0            17.543499         1.289   \n",
       "20       0.27763999      0.51756              4.68959         0.754   \n",
       "21          0.03817      0.12613            1.6087513         0.966   \n",
       "22       0.24516001      0.69391            4.1694636         1.029   \n",
       "23          0.13472      0.33495             2.606787         1.133   \n",
       "24          0.28928      0.70335             5.397871         0.645   \n",
       "25          0.30235   0.60433996             5.811433          1.06   \n",
       "26          0.30769         <NA>            3.7218654          <NA>   \n",
       "\n",
       "   Quick Ratio Return on Assets Enterprise Value Enterprise Value to EBITDA  \\\n",
       "0        0.745          0.21464    3456762118144                      25.67   \n",
       "1        1.163          0.14592    3179720212480                     23.286   \n",
       "2        3.503          0.55258    3563218010112                     58.238   \n",
       "3        1.761          0.16483    2125729103872                     17.217   \n",
       "4        0.827          0.07069    2321747804160                     20.807   \n",
       "5        2.568       0.17188999    1442350366720                     18.209   \n",
       "8         0.63          0.13946     757866496000                     45.747   \n",
       "9        2.238          0.12409    3672532582400                      2.043   \n",
       "10       0.841      0.077010006     100720377856                      4.387   \n",
       "11       1.214          0.04759    1040004087808                     78.526   \n",
       "12       0.183      0.069510005     747954503680                     18.342   \n",
       "13       0.742       0.21465999     458086383616                      3.596   \n",
       "14        <NA>      0.013259999     205751500800                       <NA>   \n",
       "15       0.833          0.06924     608368656384                     17.365   \n",
       "16       0.837          0.16174     584800665600                     23.417   \n",
       "17       0.978          0.07083     557304119296                       7.79   \n",
       "18       0.591      0.072909996     599515660288                     27.497   \n",
       "19       0.891       0.22886999     486012649472                     28.957   \n",
       "20       0.507          0.10601     417390854144                     17.362   \n",
       "21       0.391           0.0836     412516057088                     35.802   \n",
       "22       0.705          0.08403     384398131200                     12.791   \n",
       "23       0.251          0.15313     468345290752                     18.917   \n",
       "24       0.436      0.077199996     365109346304                     14.245   \n",
       "25       0.784          0.08438     301981204480                     20.361   \n",
       "26        <NA>     0.0072899996     348427976704                       <NA>   \n",
       "\n",
       "   PEG Ratio Book Value Per Share  \n",
       "0       <NA>                3.767  \n",
       "1       <NA>               38.693  \n",
       "2       <NA>                2.368  \n",
       "3       <NA>               25.613  \n",
       "4       <NA>               24.655  \n",
       "5       <NA>               65.186  \n",
       "8       <NA>               15.825  \n",
       "9       <NA>              153.888  \n",
       "10      <NA>               59.221  \n",
       "11      <NA>               21.806  \n",
       "12      <NA>               10.507  \n",
       "13      <NA>                27.07  \n",
       "14      <NA>               115.15  \n",
       "15      <NA>              102.421  \n",
       "16      <NA>               20.077  \n",
       "17      <NA>               61.112  \n",
       "18      <NA>                3.903  \n",
       "19      <NA>                8.087  \n",
       "20      <NA>               21.676  \n",
       "21      <NA>               53.308  \n",
       "22      <NA>               29.144  \n",
       "23      <NA>                5.839  \n",
       "24      <NA>                3.413  \n",
       "25      <NA>                6.153  \n",
       "26      <NA>               35.371  \n",
       "\n",
       "[25 rows x 23 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all 'Not Available' values in 'Dividend Yield' with 0.00\n",
    "df_filtered_stocks_data[\"Dividend Yield\"] = df_filtered_stocks_data[\n",
    "    \"Dividend Yield\"].replace(pd.NA, 0.00).fillna(0.00)\n",
    "df_filtered_stocks_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb54a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.221950</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46584</td>\n",
       "      <td>0.69349</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3.179720e+12</td>\n",
       "      <td>23.286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.579430</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.976350</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62057</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3.563218e+12</td>\n",
       "      <td>58.238</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.855113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32312</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2.125729e+12</td>\n",
       "      <td>17.217</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.411780</td>\n",
       "      <td>8.577570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.585892</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2.321748e+12</td>\n",
       "      <td>20.807</td>\n",
       "      <td>1.3</td>\n",
       "      <td>24.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "1   MSFT  Microsoft Corporation Common Stock  3.206167e+12   \n",
       "2   NVDA     NVIDIA Corporation Common Stock  2.864613e+12   \n",
       "3  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12   \n",
       "4   AMZN        Amazon.com Inc. Common Stock  1.940525e+12   \n",
       "\n",
       "   Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  Dividend Yield  \\\n",
       "0           37.536186          27.493536            60.584020          0.0044   \n",
       "1           35.221950          28.298223            11.032745          0.0078   \n",
       "2           68.579430          35.295135            61.976350          0.0003   \n",
       "3           23.255629          19.583218             6.855113          0.0045   \n",
       "4           45.091682          34.411780             8.577570          0.0000   \n",
       "\n",
       "   Earnings Per Share Forward  Return on Equity  Debt to Equity Ratio  ...  \\\n",
       "0                        8.31           1.57413               209.059  ...   \n",
       "1                       14.95           0.35604                33.657  ...   \n",
       "2                        4.12           1.23767                17.221  ...   \n",
       "3                        8.96           0.32101                 9.324  ...   \n",
       "4                        6.15           0.22558                61.175  ...   \n",
       "\n",
       "   Operating Margin  Gross Margin  Price to Sales Ratio  Current Ratio  \\\n",
       "0           0.31171       0.46206              8.822043          0.867   \n",
       "1           0.46584       0.69349             12.486235          1.301   \n",
       "2           0.62057       0.75976             37.380695          4.269   \n",
       "3           0.32312       0.58127              6.349746          1.950   \n",
       "4           0.10959       0.48406              3.585892          1.089   \n",
       "\n",
       "   Quick Ratio  Return on Assets  Enterprise Value  \\\n",
       "0        0.745           0.21464      3.456762e+12   \n",
       "1        1.163           0.14592      3.179720e+12   \n",
       "2        3.503           0.55258      3.563218e+12   \n",
       "3        1.761           0.16483      2.125729e+12   \n",
       "4        0.827           0.07069      2.321748e+12   \n",
       "\n",
       "   Enterprise Value to EBITDA  PEG Ratio  Book Value Per Share  \n",
       "0                      25.670        1.3                 3.767  \n",
       "1                      23.286        1.3                38.693  \n",
       "2                      58.238        1.3                 2.368  \n",
       "3                      17.217        1.3                25.613  \n",
       "4                      20.807        1.3                24.655  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of all column names in the DataFrame\n",
    "columns_to_impute = df_filtered_stocks_data.count().keys().tolist()\n",
    "\n",
    "# Exclude non-numeric columns from the list \n",
    "columns_to_impute = [col for col in columns_to_impute if col not in ['Symbol', 'Name']]\n",
    "\n",
    "# Convert columns to numeric and impute missing values with the median \n",
    "# of the respective column\n",
    "for col in columns_to_impute:\n",
    "    df_filtered_stocks_data[col] = pd.to_numeric(df_filtered_stocks_data[col], \n",
    "                                                 errors ='coerce')\n",
    "    median_value = df_filtered_stocks_data[col].median()\n",
    "    df_filtered_stocks_data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "df_filtered_stocks_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "351c0d2d-cc5d-4a66-9391-050d4f7b81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.221950</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46584</td>\n",
       "      <td>0.69349</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3.179720e+12</td>\n",
       "      <td>23.286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.579430</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.976350</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62057</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3.563218e+12</td>\n",
       "      <td>58.238</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.855113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32312</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2.125729e+12</td>\n",
       "      <td>17.217</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.411780</td>\n",
       "      <td>8.577570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.585892</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2.321748e+12</td>\n",
       "      <td>20.807</td>\n",
       "      <td>1.3</td>\n",
       "      <td>24.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>Meta Platforms Inc. Class A Common Stock</td>\n",
       "      <td>1.349101e+12</td>\n",
       "      <td>27.263107</td>\n",
       "      <td>22.794006</td>\n",
       "      <td>8.854049</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>25.30</td>\n",
       "      <td>0.36134</td>\n",
       "      <td>29.811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42765</td>\n",
       "      <td>0.81501</td>\n",
       "      <td>9.326395</td>\n",
       "      <td>2.732</td>\n",
       "      <td>2.568</td>\n",
       "      <td>0.17189</td>\n",
       "      <td>1.442350e+12</td>\n",
       "      <td>18.209</td>\n",
       "      <td>1.3</td>\n",
       "      <td>65.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LLY</td>\n",
       "      <td>Eli Lilly and Company Common Stock</td>\n",
       "      <td>8.777562e+11</td>\n",
       "      <td>84.997830</td>\n",
       "      <td>34.744507</td>\n",
       "      <td>49.682780</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>22.66</td>\n",
       "      <td>0.65318</td>\n",
       "      <td>218.081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39774</td>\n",
       "      <td>0.80906</td>\n",
       "      <td>18.265305</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.13946</td>\n",
       "      <td>7.578665e+11</td>\n",
       "      <td>45.747</td>\n",
       "      <td>1.3</td>\n",
       "      <td>15.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TSM</td>\n",
       "      <td>Taiwan Semiconductor Manufacturing Company Ltd.</td>\n",
       "      <td>8.769189e+11</td>\n",
       "      <td>33.902878</td>\n",
       "      <td>21.246187</td>\n",
       "      <td>1.224917</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>8.08</td>\n",
       "      <td>0.28027</td>\n",
       "      <td>24.081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47488</td>\n",
       "      <td>0.54453</td>\n",
       "      <td>0.368705</td>\n",
       "      <td>2.567</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.12409</td>\n",
       "      <td>3.672533e+12</td>\n",
       "      <td>2.043</td>\n",
       "      <td>1.3</td>\n",
       "      <td>153.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AVGO</td>\n",
       "      <td>Broadcom Inc. Common Stock</td>\n",
       "      <td>7.660679e+11</td>\n",
       "      <td>138.520320</td>\n",
       "      <td>27.499495</td>\n",
       "      <td>2.877020</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>6.17</td>\n",
       "      <td>0.12509</td>\n",
       "      <td>166.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31765</td>\n",
       "      <td>0.74713</td>\n",
       "      <td>16.998260</td>\n",
       "      <td>1.038</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.07701</td>\n",
       "      <td>1.007204e+11</td>\n",
       "      <td>4.387</td>\n",
       "      <td>1.3</td>\n",
       "      <td>59.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla Inc. Common Stock</td>\n",
       "      <td>7.244806e+11</td>\n",
       "      <td>84.790184</td>\n",
       "      <td>95.366810</td>\n",
       "      <td>14.270384</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.20389</td>\n",
       "      <td>18.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10789</td>\n",
       "      <td>0.18229</td>\n",
       "      <td>10.282105</td>\n",
       "      <td>1.844</td>\n",
       "      <td>1.214</td>\n",
       "      <td>0.04759</td>\n",
       "      <td>1.040004e+12</td>\n",
       "      <td>78.526</td>\n",
       "      <td>1.3</td>\n",
       "      <td>21.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol                                             Name    Market Cap  \\\n",
       "0    AAPL                          Apple Inc. Common Stock  3.288959e+12   \n",
       "1    MSFT               Microsoft Corporation Common Stock  3.206167e+12   \n",
       "2    NVDA                  NVIDIA Corporation Common Stock  2.864613e+12   \n",
       "3   GOOGL               Alphabet Inc. Class A Common Stock  1.945719e+12   \n",
       "4    AMZN                     Amazon.com Inc. Common Stock  1.940525e+12   \n",
       "5    META         Meta Platforms Inc. Class A Common Stock  1.349101e+12   \n",
       "8     LLY               Eli Lilly and Company Common Stock  8.777562e+11   \n",
       "9     TSM  Taiwan Semiconductor Manufacturing Company Ltd.  8.769189e+11   \n",
       "10   AVGO                       Broadcom Inc. Common Stock  7.660679e+11   \n",
       "11   TSLA                          Tesla Inc. Common Stock  7.244806e+11   \n",
       "\n",
       "    Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  \\\n",
       "0            37.536186          27.493536            60.584020   \n",
       "1            35.221950          28.298223            11.032745   \n",
       "2            68.579430          35.295135            61.976350   \n",
       "3            23.255629          19.583218             6.855113   \n",
       "4            45.091682          34.411780             8.577570   \n",
       "5            27.263107          22.794006             8.854049   \n",
       "8            84.997830          34.744507            49.682780   \n",
       "9            33.902878          21.246187             1.224917   \n",
       "10          138.520320          27.499495             2.877020   \n",
       "11           84.790184          95.366810            14.270384   \n",
       "\n",
       "    Dividend Yield  Earnings Per Share Forward  Return on Equity  \\\n",
       "0           0.0044                        8.31           1.57413   \n",
       "1           0.0078                       14.95           0.35604   \n",
       "2           0.0003                        4.12           1.23767   \n",
       "3           0.0045                        8.96           0.32101   \n",
       "4           0.0000                        6.15           0.22558   \n",
       "5           0.0034                       25.30           0.36134   \n",
       "8           0.0064                       22.66           0.65318   \n",
       "9           0.0132                        8.08           0.28027   \n",
       "10          0.0122                        6.17           0.12509   \n",
       "11          0.0000                        3.24           0.20389   \n",
       "\n",
       "    Debt to Equity Ratio  ...  Operating Margin  Gross Margin  \\\n",
       "0                209.059  ...           0.31171       0.46206   \n",
       "1                 33.657  ...           0.46584       0.69349   \n",
       "2                 17.221  ...           0.62057       0.75976   \n",
       "3                  9.324  ...           0.32312       0.58127   \n",
       "4                 61.175  ...           0.10959       0.48406   \n",
       "5                 29.811  ...           0.42765       0.81501   \n",
       "8                218.081  ...           0.39774       0.80906   \n",
       "9                 24.081  ...           0.47488       0.54453   \n",
       "10               166.032  ...           0.31765       0.74713   \n",
       "11                18.078  ...           0.10789       0.18229   \n",
       "\n",
       "    Price to Sales Ratio  Current Ratio  Quick Ratio  Return on Assets  \\\n",
       "0               8.822043          0.867        0.745           0.21464   \n",
       "1              12.486235          1.301        1.163           0.14592   \n",
       "2              37.380695          4.269        3.503           0.55258   \n",
       "3               6.349746          1.950        1.761           0.16483   \n",
       "4               3.585892          1.089        0.827           0.07069   \n",
       "5               9.326395          2.732        2.568           0.17189   \n",
       "8              18.265305          1.273        0.630           0.13946   \n",
       "9               0.368705          2.567        2.238           0.12409   \n",
       "10             16.998260          1.038        0.841           0.07701   \n",
       "11             10.282105          1.844        1.214           0.04759   \n",
       "\n",
       "    Enterprise Value  Enterprise Value to EBITDA  PEG Ratio  \\\n",
       "0       3.456762e+12                      25.670        1.3   \n",
       "1       3.179720e+12                      23.286        1.3   \n",
       "2       3.563218e+12                      58.238        1.3   \n",
       "3       2.125729e+12                      17.217        1.3   \n",
       "4       2.321748e+12                      20.807        1.3   \n",
       "5       1.442350e+12                      18.209        1.3   \n",
       "8       7.578665e+11                      45.747        1.3   \n",
       "9       3.672533e+12                       2.043        1.3   \n",
       "10      1.007204e+11                       4.387        1.3   \n",
       "11      1.040004e+12                      78.526        1.3   \n",
       "\n",
       "    Book Value Per Share  \n",
       "0                  3.767  \n",
       "1                 38.693  \n",
       "2                  2.368  \n",
       "3                 25.613  \n",
       "4                 24.655  \n",
       "5                 65.186  \n",
       "8                 15.825  \n",
       "9                153.888  \n",
       "10                59.221  \n",
       "11                21.806  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_stocks_data = df_filtered_stocks_data[\n",
    "    (df_filtered_stocks_data['Symbol'] != \"NaN\")]\n",
    "df_filtered_stocks_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d852a",
   "metadata": {},
   "source": [
    "## Classification Variables\n",
    "Now that we have a substantial amount of quantitative variables, we are going to add two classification variables to our DataFrame: 'Pays Dividend' and 'Earnings Outcome'. Even though we are creating this model to predict 'Earnings Outcome', I included 'Pays Dividend' because it creates a richer feature set, companies that pay dividends have a different risk profile and may be more stable, and further insights can be derived from seeing the influence that dividend payments have on earnigns reports. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cae545",
   "metadata": {},
   "source": [
    "## Classification Variables: Pays Dividend\n",
    "We are going to add a 'Pays Dividend' column to the 'df_stocks_data' DataFrame using the values in the \"Dividend Yield\" column. To do this, we're going to analyze the values in the \"Dividend Yield\" column and replace all values that are 0.000 with \"No\" and any other values with \"Yes\". Since all values in the \"Dividend Yield column are 0 or greater, we do not have to specify if the value is positive or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfa16f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Pays Dividend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.46206</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.221950</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69349</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3.179720e+12</td>\n",
       "      <td>23.286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38.693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>2.864613e+12</td>\n",
       "      <td>68.579430</td>\n",
       "      <td>35.295135</td>\n",
       "      <td>61.976350</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.23767</td>\n",
       "      <td>17.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75976</td>\n",
       "      <td>37.380695</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.503</td>\n",
       "      <td>0.55258</td>\n",
       "      <td>3.563218e+12</td>\n",
       "      <td>58.238</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>1.945719e+12</td>\n",
       "      <td>23.255629</td>\n",
       "      <td>19.583218</td>\n",
       "      <td>6.855113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>8.96</td>\n",
       "      <td>0.32101</td>\n",
       "      <td>9.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58127</td>\n",
       "      <td>6.349746</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1.761</td>\n",
       "      <td>0.16483</td>\n",
       "      <td>2.125729e+12</td>\n",
       "      <td>17.217</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc. Common Stock</td>\n",
       "      <td>1.940525e+12</td>\n",
       "      <td>45.091682</td>\n",
       "      <td>34.411780</td>\n",
       "      <td>8.577570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.22558</td>\n",
       "      <td>61.175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48406</td>\n",
       "      <td>3.585892</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.07069</td>\n",
       "      <td>2.321748e+12</td>\n",
       "      <td>20.807</td>\n",
       "      <td>1.3</td>\n",
       "      <td>24.655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "1   MSFT  Microsoft Corporation Common Stock  3.206167e+12   \n",
       "2   NVDA     NVIDIA Corporation Common Stock  2.864613e+12   \n",
       "3  GOOGL  Alphabet Inc. Class A Common Stock  1.945719e+12   \n",
       "4   AMZN        Amazon.com Inc. Common Stock  1.940525e+12   \n",
       "\n",
       "   Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  Dividend Yield  \\\n",
       "0           37.536186          27.493536            60.584020          0.0044   \n",
       "1           35.221950          28.298223            11.032745          0.0078   \n",
       "2           68.579430          35.295135            61.976350          0.0003   \n",
       "3           23.255629          19.583218             6.855113          0.0045   \n",
       "4           45.091682          34.411780             8.577570          0.0000   \n",
       "\n",
       "   Earnings Per Share Forward  Return on Equity  Debt to Equity Ratio  ...  \\\n",
       "0                        8.31           1.57413               209.059  ...   \n",
       "1                       14.95           0.35604                33.657  ...   \n",
       "2                        4.12           1.23767                17.221  ...   \n",
       "3                        8.96           0.32101                 9.324  ...   \n",
       "4                        6.15           0.22558                61.175  ...   \n",
       "\n",
       "   Gross Margin  Price to Sales Ratio  Current Ratio  Quick Ratio  \\\n",
       "0       0.46206              8.822043          0.867        0.745   \n",
       "1       0.69349             12.486235          1.301        1.163   \n",
       "2       0.75976             37.380695          4.269        3.503   \n",
       "3       0.58127              6.349746          1.950        1.761   \n",
       "4       0.48406              3.585892          1.089        0.827   \n",
       "\n",
       "   Return on Assets  Enterprise Value  Enterprise Value to EBITDA  PEG Ratio  \\\n",
       "0           0.21464      3.456762e+12                      25.670        1.3   \n",
       "1           0.14592      3.179720e+12                      23.286        1.3   \n",
       "2           0.55258      3.563218e+12                      58.238        1.3   \n",
       "3           0.16483      2.125729e+12                      17.217        1.3   \n",
       "4           0.07069      2.321748e+12                      20.807        1.3   \n",
       "\n",
       "   Book Value Per Share  Pays Dividend  \n",
       "0                 3.767              1  \n",
       "1                38.693              1  \n",
       "2                 2.368              1  \n",
       "3                25.613              1  \n",
       "4                24.655              0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all 0.00 values with 0 and any other values with 1\n",
    "df_filtered_stocks_data['Pays Dividend'] = df_filtered_stocks_data[\n",
    "    \"Dividend Yield\"].apply(lambda x: 0 if x == 0.0000 else 1)\n",
    "df_filtered_stocks_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0c21d",
   "metadata": {},
   "source": [
    "## Classification Variables: Earnings Outcome\n",
    "Earnings outcome is the variable we are going to built our model to try and predict. For stock traders, the important values in earnings reports are \"Actual EPS\" and \"Predicted EPS\". \"Predicted EPS\" are predictions done by financial firms prior to the earnings report and \"Actual EPS\" are the actual earnings as revealed by the company. We can use yfinance to pull this data from yahoo finance, with the limitation being we can ony pull the last 4 quarters of earnings reports. Because this is a computationally intensive program to run on a simple laptop, I saved the output as a HDF5 file for easy access. Once this is done, we will create our target classification variable, which is 'Earnings Outcome'. Earnings outcome will have a value of 1 if the EPS Difference (Actual EPS - Estimated EPS) is greater than 0 and a value of 0 if the EPS Difference is 0 or less. In this case, an earnings outcome of 1 is positive and an earnings outcome of 0 is negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c1b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is computationally intensive and will take some time\n",
    "# to run. After running, save it as an HDF5 file, as shown below\n",
    "import yfinance as yf\n",
    "\n",
    "# Extract the 'Symbol' column from the DataFrame\n",
    "stock_symbols = df_filtered_stocks_data[\"Symbol\"]\n",
    "\n",
    "# Dictionary to store earnings data for each stock\n",
    "earnings_data = {}\n",
    "\n",
    "# Function to fetch earnings history for a chunk of stock symbols\n",
    "def fetch_earnings(symbols_chunk):\n",
    "    for symbol in stock_symbols:\n",
    "        stock=yf.Ticker(symbol) # Creates a Ticker object for the stock symbol\n",
    "        earnings_history = stock.earnings_history # Fetch the earnings history\n",
    "    \n",
    "        # Check if earnings_history is None (no data returned)\n",
    "        if earnings_history is not None:\n",
    "            # Convert to DataFrame\n",
    "            earnings_df = pd.DataFrame(earnings_history)\n",
    "        \n",
    "            # Check if the DataFrame has rows\n",
    "            if not earnings_df.empty:\n",
    "                print(f\"Earnings history for {symbol}:\")\n",
    "                print(earnings_df.head())\n",
    "                earnings_data[symbol] = earnings_df\n",
    "            else:\n",
    "                print(f\"No earnings data available for {symbol}\")\n",
    "        else:\n",
    "            print(f\"No earnings data available for {symbol}\")\n",
    "\n",
    "# Process symbols in chunks of 1000\n",
    "chunk_size = 1000\n",
    "for i in range(0, len(stock_symbols), chunk_size):\n",
    "    symbols_chunk = stock_symbols[i:i + chunk_size]\n",
    "    print(f\"Processing chunk {i // chunk_size + 1}...\")\n",
    "    fetch_earnings(symbols_chunk.head(25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd6834-51e4-4f26-bd88-3a4c4bee7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save earnings data to an HDF5 file\n",
    "#with pd.HDFStore('earnings_data.h5', mode='w') as store:\n",
    "#    for symbal, df in earnings_data.items():\n",
    "        # Store each earnings DataFrame using its symbol as the key\n",
    "#        store[symbal] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1b6aa68-8f40-4190-b3ef-bd3fb93c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the loaded earnings data\n",
    "loaded_earnings_data = {}\n",
    "\n",
    "# Open the HDF5 file in read mode\n",
    "with pd.HDFStore('earnings_data.h5', mode='r') as store:\n",
    "    # Iterate through all stored keys (symbols) in the HDF5 file\n",
    "    for symbol in store.keys():\n",
    "        # Remove leading '/' from the symbol name\n",
    "        symbol = symbol.strip('/')\n",
    "        # Load the DataFrame and add it to the dictionary\n",
    "        loaded_earnings_data[symbol] = store[symbol]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b55e62ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/49phbq0x3bj2l3xqln6zr3x40000gn/T/ipykernel_5559/397766636.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  earnings_df = pd.concat(loaded_earnings_data.values(),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>epsEstimate</th>\n",
       "      <th>epsActual</th>\n",
       "      <th>epsDifference</th>\n",
       "      <th>surprisePercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>A</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>A</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30</th>\n",
       "      <td>A</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31</th>\n",
       "      <td>A</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>AA</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol  epsEstimate  epsActual  epsDifference  surprisePercent\n",
       "2023-10-31      A         1.34       1.38           0.04            0.030\n",
       "2024-01-31      A         1.22       1.29           0.07            0.057\n",
       "2024-04-30      A         1.19       1.22           0.03            0.025\n",
       "2024-07-31      A         1.26       1.32           0.06            0.048\n",
       "2023-12-31     AA        -0.86      -0.56           0.30            0.349"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all DataFrames in the loaded earnings data dictionary into \n",
    "# a single DataFrame\n",
    "# Use the dictionary keys (stock symbols) as a multi-index for the rows \n",
    "earnings_df = pd.concat(loaded_earnings_data.values(), \n",
    "                        keys=loaded_earnings_data.keys())\n",
    "\n",
    "# Reset the multi-index to move the 'symbol' from the index to a column\n",
    "# Rename the new column to 'Symbol' for clarity\n",
    "earnings_df = earnings_df.reset_index(level=0).rename(columns={'level_0': 'Symbol'})\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bd2b757-fde8-4455-a6ac-9f567a675ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>epsEstimate</th>\n",
       "      <th>epsActual</th>\n",
       "      <th>epsDifference</th>\n",
       "      <th>surprisePercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>A</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Symbol  epsEstimate  epsActual  epsDifference  surprisePercent\n",
       "0 2023-10-31      A         1.34       1.38           0.04            0.030\n",
       "1 2024-01-31      A         1.22       1.29           0.07            0.057\n",
       "2 2024-04-30      A         1.19       1.22           0.03            0.025\n",
       "3 2024-07-31      A         1.26       1.32           0.06            0.048\n",
       "4 2023-12-31     AA        -0.86      -0.56           0.30            0.349"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index and make 'Date' it's own column\n",
    "earnings_df = earnings_df.reset_index().rename(columns={'index': 'Date'})\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6757421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>epsEstimate</th>\n",
       "      <th>epsActual</th>\n",
       "      <th>epsDifference</th>\n",
       "      <th>surprisePercent</th>\n",
       "      <th>Earnings Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>A</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>A</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>AA</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Symbol  epsEstimate  epsActual  epsDifference  surprisePercent  \\\n",
       "0 2023-10-31      A         1.34       1.38           0.04            0.030   \n",
       "1 2024-01-31      A         1.22       1.29           0.07            0.057   \n",
       "2 2024-04-30      A         1.19       1.22           0.03            0.025   \n",
       "3 2024-07-31      A         1.26       1.32           0.06            0.048   \n",
       "4 2023-12-31     AA        -0.86      -0.56           0.30            0.349   \n",
       "\n",
       "   Earnings Outcome  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column called 'Earnings Outcome' which is a classification variable \n",
    "# and the target of our analysis\n",
    "# All values greater than 0 in the 'epsDifference' column are assigned 1 \n",
    "# and all values that are \n",
    "# 0 or less are assigned a value of 0\n",
    "earnings_df['Earnings Outcome'] = earnings_df[\n",
    "    'epsDifference'].apply(lambda x: 1 if x > 0 else 0)\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee369f-9f83-4dc1-b9f9-08332c86eef8",
   "metadata": {},
   "source": [
    "## Merge DataFrames\n",
    "Now that we have a clean DataFrame with our earnings history information, we can merge it with our other DataFrame containing the stock's valuation parameters using the shared column 'Symbol'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a00cc391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Pays Dividend</th>\n",
       "      <th>Date</th>\n",
       "      <th>epsEstimate</th>\n",
       "      <th>epsActual</th>\n",
       "      <th>epsDifference</th>\n",
       "      <th>surprisePercent</th>\n",
       "      <th>Earnings Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.221950</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>23.286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38.693</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "1   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "2   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "3   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "4   MSFT  Microsoft Corporation Common Stock  3.206167e+12   \n",
       "\n",
       "   Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  Dividend Yield  \\\n",
       "0           37.536186          27.493536            60.584020          0.0044   \n",
       "1           37.536186          27.493536            60.584020          0.0044   \n",
       "2           37.536186          27.493536            60.584020          0.0044   \n",
       "3           37.536186          27.493536            60.584020          0.0044   \n",
       "4           35.221950          28.298223            11.032745          0.0078   \n",
       "\n",
       "   Earnings Per Share Forward  Return on Equity  Debt to Equity Ratio  ...  \\\n",
       "0                        8.31           1.57413               209.059  ...   \n",
       "1                        8.31           1.57413               209.059  ...   \n",
       "2                        8.31           1.57413               209.059  ...   \n",
       "3                        8.31           1.57413               209.059  ...   \n",
       "4                       14.95           0.35604                33.657  ...   \n",
       "\n",
       "   Enterprise Value to EBITDA  PEG Ratio  Book Value Per Share  Pays Dividend  \\\n",
       "0                      25.670        1.3                 3.767              1   \n",
       "1                      25.670        1.3                 3.767              1   \n",
       "2                      25.670        1.3                 3.767              1   \n",
       "3                      25.670        1.3                 3.767              1   \n",
       "4                      23.286        1.3                38.693              1   \n",
       "\n",
       "        Date  epsEstimate  epsActual  epsDifference  surprisePercent  \\\n",
       "0 2023-12-31         2.10       2.18           0.08            0.038   \n",
       "1 2024-03-31         1.50       1.53           0.03            0.020   \n",
       "2 2024-06-30         1.35       1.40           0.05            0.037   \n",
       "3 2024-09-30         1.60       1.64           0.04            0.025   \n",
       "4 2023-12-31         2.78       2.93           0.15            0.054   \n",
       "\n",
       "   Earnings Outcome  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge our earnings history DataFrame with our valuation parameters DataFrame\n",
    "# using the shared column 'Symbol'\n",
    "\n",
    "df_stocks_data_merged = pd.merge(df_filtered_stocks_data, earnings_df, on=\"Symbol\")\n",
    "df_stocks_data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f167ba-2cca-424a-80ce-88a52625fa34",
   "metadata": {},
   "source": [
    "## Data Cleanup: Remove Unavailable values\n",
    "Since earnings history is very important to our model, we're going to remove any rows where the EPS Difference is unavailable. Following our data imputation, we'll also finalize our data cleaning by removing any leftover rows which have unavailable or NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5abf04a4-808f-4b0f-a36c-f50473a89cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol                        12091\n",
       "Name                          12091\n",
       "Market Cap                    12091\n",
       "Trailing P/E Ratio            12091\n",
       "Forward P/E Ratio             12091\n",
       "Price to Book Ratio           12091\n",
       "Dividend Yield                12091\n",
       "Earnings Per Share Forward    12091\n",
       "Return on Equity              12091\n",
       "Debt to Equity Ratio          12091\n",
       "Free Cash Flow                12091\n",
       "Revenue Growth                12091\n",
       "Beta (Volatility)             12091\n",
       "Operating Margin              12091\n",
       "Gross Margin                  12091\n",
       "Price to Sales Ratio          12091\n",
       "Current Ratio                 12091\n",
       "Quick Ratio                   12091\n",
       "Return on Assets              12091\n",
       "Enterprise Value              12091\n",
       "Enterprise Value to EBITDA    12091\n",
       "PEG Ratio                     12091\n",
       "Book Value Per Share          12091\n",
       "Pays Dividend                 12091\n",
       "Date                          12091\n",
       "epsEstimate                   12091\n",
       "epsActual                     12091\n",
       "epsDifference                 12091\n",
       "surprisePercent               11964\n",
       "Earnings Outcome              12091\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows where 'epsDifference' is unavailable\n",
    "\n",
    "df_stocks_data_merged = df_stocks_data_merged.dropna(subset=['epsDifference'])\n",
    "df_stocks_data_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c487af30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol                        11964\n",
       "Name                          11964\n",
       "Market Cap                    11964\n",
       "Trailing P/E Ratio            11964\n",
       "Forward P/E Ratio             11964\n",
       "Price to Book Ratio           11964\n",
       "Dividend Yield                11964\n",
       "Earnings Per Share Forward    11964\n",
       "Return on Equity              11964\n",
       "Debt to Equity Ratio          11964\n",
       "Free Cash Flow                11964\n",
       "Revenue Growth                11964\n",
       "Beta (Volatility)             11964\n",
       "Operating Margin              11964\n",
       "Gross Margin                  11964\n",
       "Price to Sales Ratio          11964\n",
       "Current Ratio                 11964\n",
       "Quick Ratio                   11964\n",
       "Return on Assets              11964\n",
       "Enterprise Value              11964\n",
       "Enterprise Value to EBITDA    11964\n",
       "PEG Ratio                     11964\n",
       "Book Value Per Share          11964\n",
       "Pays Dividend                 11964\n",
       "Date                          11964\n",
       "epsEstimate                   11964\n",
       "epsActual                     11964\n",
       "epsDifference                 11964\n",
       "surprisePercent               11964\n",
       "Earnings Outcome              11964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any remaining rows that are 'Not Available' or NaN\n",
    "import numpy as np\n",
    "\n",
    "df_stocks_data_merged = df_stocks_data_merged.replace(\"Not Available\", np.nan)\n",
    "df_stocks_data_merged = df_stocks_data_merged.dropna()\n",
    "df_stocks_data_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02ee532a-b835-4c71-9e1e-7db293dc22b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numerical values per column:\n",
      "Symbol                        11964\n",
      "Name                          11964\n",
      "Market Cap                        0\n",
      "Trailing P/E Ratio                0\n",
      "Forward P/E Ratio                 0\n",
      "Price to Book Ratio               0\n",
      "Dividend Yield                    0\n",
      "Earnings Per Share Forward        0\n",
      "Return on Equity                  0\n",
      "Debt to Equity Ratio              0\n",
      "Free Cash Flow                    0\n",
      "Revenue Growth                    0\n",
      "Beta (Volatility)                 0\n",
      "Operating Margin                  0\n",
      "Gross Margin                      0\n",
      "Price to Sales Ratio              0\n",
      "Current Ratio                     0\n",
      "Quick Ratio                       0\n",
      "Return on Assets                  0\n",
      "Enterprise Value                  0\n",
      "Enterprise Value to EBITDA        0\n",
      "PEG Ratio                         0\n",
      "Book Value Per Share              0\n",
      "Pays Dividend                     0\n",
      "Date                              0\n",
      "epsEstimate                       0\n",
      "epsActual                         0\n",
      "epsDifference                     0\n",
      "surprisePercent                   0\n",
      "Earnings Outcome                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This is to make sure that our numerical columns don't \n",
    "# contain non-numerical values\n",
    "\n",
    "non_numerical = df_stocks_data_merged.apply(pd.to_numeric, errors='coerce')\n",
    "non_numerical_na = non_numerical.isna().sum()\n",
    "\n",
    "print(\"Non-numerical values per column:\")\n",
    "print(non_numerical_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20522212-ccfb-4cd7-ba30-a4004df2646c",
   "metadata": {},
   "source": [
    "## Data Leakage\n",
    "Data leakage happens when there is information used in the model that directly or indirectly provides the answer to the target variable, leading to overly optimistic model performance. To mitigate this, we need to remove the earnings information, including EPS Difference, EPS Estimate, EPS Actual, and Surprise Percent, as leaving these in will provide the model information to perfectly predict the target variable, Earnings Outcome. On top of this, we are also going to drop 'Date' is that is not needed and cannot be included in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56d2c03d-847d-497d-b83b-62393b75172e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Pays Dividend</th>\n",
       "      <th>Earnings Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>3.288959e+12</td>\n",
       "      <td>37.536186</td>\n",
       "      <td>27.493536</td>\n",
       "      <td>60.584020</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>8.31</td>\n",
       "      <td>1.57413</td>\n",
       "      <td>209.059</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822043</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.21464</td>\n",
       "      <td>3.456762e+12</td>\n",
       "      <td>25.670</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>3.206167e+12</td>\n",
       "      <td>35.221950</td>\n",
       "      <td>28.298223</td>\n",
       "      <td>11.032745</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>14.95</td>\n",
       "      <td>0.35604</td>\n",
       "      <td>33.657</td>\n",
       "      <td>...</td>\n",
       "      <td>12.486235</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.14592</td>\n",
       "      <td>3.179720e+12</td>\n",
       "      <td>23.286</td>\n",
       "      <td>1.3</td>\n",
       "      <td>38.693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name    Market Cap  \\\n",
       "0   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "1   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "2   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "3   AAPL             Apple Inc. Common Stock  3.288959e+12   \n",
       "4   MSFT  Microsoft Corporation Common Stock  3.206167e+12   \n",
       "\n",
       "   Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  Dividend Yield  \\\n",
       "0           37.536186          27.493536            60.584020          0.0044   \n",
       "1           37.536186          27.493536            60.584020          0.0044   \n",
       "2           37.536186          27.493536            60.584020          0.0044   \n",
       "3           37.536186          27.493536            60.584020          0.0044   \n",
       "4           35.221950          28.298223            11.032745          0.0078   \n",
       "\n",
       "   Earnings Per Share Forward  Return on Equity  Debt to Equity Ratio  ...  \\\n",
       "0                        8.31           1.57413               209.059  ...   \n",
       "1                        8.31           1.57413               209.059  ...   \n",
       "2                        8.31           1.57413               209.059  ...   \n",
       "3                        8.31           1.57413               209.059  ...   \n",
       "4                       14.95           0.35604                33.657  ...   \n",
       "\n",
       "   Price to Sales Ratio  Current Ratio  Quick Ratio  Return on Assets  \\\n",
       "0              8.822043          0.867        0.745           0.21464   \n",
       "1              8.822043          0.867        0.745           0.21464   \n",
       "2              8.822043          0.867        0.745           0.21464   \n",
       "3              8.822043          0.867        0.745           0.21464   \n",
       "4             12.486235          1.301        1.163           0.14592   \n",
       "\n",
       "   Enterprise Value  Enterprise Value to EBITDA  PEG Ratio  \\\n",
       "0      3.456762e+12                      25.670        1.3   \n",
       "1      3.456762e+12                      25.670        1.3   \n",
       "2      3.456762e+12                      25.670        1.3   \n",
       "3      3.456762e+12                      25.670        1.3   \n",
       "4      3.179720e+12                      23.286        1.3   \n",
       "\n",
       "   Book Value Per Share  Pays Dividend  Earnings Outcome  \n",
       "0                 3.767              1                 1  \n",
       "1                 3.767              1                 1  \n",
       "2                 3.767              1                 1  \n",
       "3                 3.767              1                 1  \n",
       "4                38.693              1                 1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To prevent data leakage, some columns need to be dropped as they either indirectly\n",
    "# provide the model with the target value answer or are in perfect multicollinearity \n",
    "# with the target variable\n",
    "\n",
    "df_stocks_data_merged.drop(columns=[\"epsDifference\", \"epsEstimate\", \"epsActual\", \n",
    "                                    \"surprisePercent\", \"Date\"], inplace=True)\n",
    "df_stocks_data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63bb91-8dfa-40c8-8ae5-a253ebcbe265",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "Scaling is the process of transforming quantitative data into a consistent range or scale. This is done to ensure that the values of features in our dataset to not significantly vary in magnitude, as these differences in scale can cause the model to bias larger values. Since the values of some of our columns are fractional and our market cap column contains values up to $1 trillion, the values need to be standardized. Scaling takes all the data and normalizes it to have a mean of 0 and a standard deviation of 1. \n",
    "\n",
    "Before scaling our values, we need to make sure that all values are numerical (which we have done above) and that there are no infinite values. As you see below, there are some infinite values in our data that need to be removed. We will remove them by replacing them with median imputation. Once this is done, we can normalize the data to a standard scale for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bb7eb78-fd48-420a-8075-ee22a06e052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/49phbq0x3bj2l3xqln6zr3x40000gn/T/ipykernel_5559/1759544207.py:16: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  \"Book Value Per Share\"]].applymap(np.isinf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Symbol                                         Name    Market Cap  \\\n",
      "2360     KEY                         KeyCorp Common Stock  1.534579e+10   \n",
      "2361     KEY                         KeyCorp Common Stock  1.534579e+10   \n",
      "2362     KEY                         KeyCorp Common Stock  1.534579e+10   \n",
      "2363     KEY                         KeyCorp Common Stock  1.534579e+10   \n",
      "4328     IRT  Independence Realty Trust Inc. Common Stock  4.747794e+09   \n",
      "...      ...                                          ...           ...   \n",
      "13323   GANX          Gain Therapeutics Inc. Common Stock  3.779248e+07   \n",
      "13428   UNCY     Unicycive Therapeutics Inc. Common Stock  3.541189e+07   \n",
      "13429   UNCY     Unicycive Therapeutics Inc. Common Stock  3.541189e+07   \n",
      "13430   UNCY     Unicycive Therapeutics Inc. Common Stock  3.541189e+07   \n",
      "13431   UNCY     Unicycive Therapeutics Inc. Common Stock  3.541189e+07   \n",
      "\n",
      "       Trailing P/E Ratio  Forward P/E Ratio  Price to Book Ratio  \\\n",
      "2360                  inf          12.327231             1.321914   \n",
      "2361                  inf          12.327231             1.321914   \n",
      "2362                  inf          12.327231             1.321914   \n",
      "2363                  inf          12.327231             1.321914   \n",
      "4328                  inf          78.477875             1.396517   \n",
      "...                   ...                ...                  ...   \n",
      "13323            20.80899          -1.917582             3.728632   \n",
      "13428            20.80899          -1.261972             1.973991   \n",
      "13429            20.80899          -1.261972             1.973991   \n",
      "13430            20.80899          -1.261972             1.973991   \n",
      "13431            20.80899          -1.261972             1.973991   \n",
      "\n",
      "       Dividend Yield  Earnings Per Share Forward  Return on Equity  \\\n",
      "2360           0.0430                        1.56           0.00967   \n",
      "2361           0.0430                        1.56           0.00967   \n",
      "2362           0.0430                        1.56           0.00967   \n",
      "2363           0.0430                        1.56           0.00967   \n",
      "4328           0.0306                        0.27          -0.00015   \n",
      "...               ...                         ...               ...   \n",
      "13323          0.0000                       -0.89          -1.88827   \n",
      "13428          0.0000                       -0.20          -1.21763   \n",
      "13429          0.0000                       -0.20          -1.21763   \n",
      "13430          0.0000                       -0.20          -1.21763   \n",
      "13431          0.0000                       -0.20          -1.21763   \n",
      "\n",
      "       Debt to Equity Ratio  ...  Price to Sales Ratio  Current Ratio  \\\n",
      "2360                55.0375  ...              3.910379          1.811   \n",
      "2361                55.0375  ...              3.910379          1.811   \n",
      "2362                55.0375  ...              3.910379          1.811   \n",
      "2363                55.0375  ...              3.910379          1.811   \n",
      "4328                65.6610  ...              7.507696          0.374   \n",
      "...                     ...  ...                   ...            ...   \n",
      "13323                6.8530  ...                   inf          2.842   \n",
      "13428                2.0230  ...                   inf          3.366   \n",
      "13429                2.0230  ...                   inf          3.366   \n",
      "13430                2.0230  ...                   inf          3.366   \n",
      "13431                2.0230  ...                   inf          3.366   \n",
      "\n",
      "       Quick Ratio  Return on Assets  Enterprise Value  \\\n",
      "2360         1.221           0.00077      3.775594e+10   \n",
      "2361         1.221           0.00077      3.775594e+10   \n",
      "2362         1.221           0.00077      3.775594e+10   \n",
      "2363         1.221           0.00077      3.775594e+10   \n",
      "4328         0.203           0.01276      7.086861e+09   \n",
      "...            ...               ...               ...   \n",
      "13323        2.644          -0.72955      3.570824e+07   \n",
      "13428        3.193          -0.53371      5.015270e+07   \n",
      "13429        3.193          -0.53371      5.015270e+07   \n",
      "13430        3.193          -0.53371      5.015270e+07   \n",
      "13431        3.193          -0.53371      5.015270e+07   \n",
      "\n",
      "       Enterprise Value to EBITDA  PEG Ratio  Book Value Per Share  \\\n",
      "2360                        9.694        1.3                14.479   \n",
      "2361                        9.694        1.3                14.479   \n",
      "2362                        9.694        1.3                14.479   \n",
      "2363                        9.694        1.3                14.479   \n",
      "4328                       20.429        1.3                14.930   \n",
      "...                           ...        ...                   ...   \n",
      "13323                      -1.636        1.3                 0.468   \n",
      "13428                      -1.739        1.3                -0.341   \n",
      "13429                      -1.739        1.3                -0.341   \n",
      "13430                      -1.739        1.3                -0.341   \n",
      "13431                      -1.739        1.3                -0.341   \n",
      "\n",
      "       Pays Dividend  Earnings Outcome  \n",
      "2360               1                 1  \n",
      "2361               1                 0  \n",
      "2362               1                 1  \n",
      "2363               1                 1  \n",
      "4328               1                 0  \n",
      "...              ...               ...  \n",
      "13323              0                 0  \n",
      "13428              0                 0  \n",
      "13429              0                 0  \n",
      "13430              0                 0  \n",
      "13431              0                 1  \n",
      "\n",
      "[80 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Upon trying to scale our values for modeling, we were given an error saying \n",
    "# some of our values\n",
    "# were infinite\n",
    "# This identifies and prints out rows with infinite values\n",
    "\n",
    "infinity_values = df_stocks_data_merged[\n",
    "    [\"Market Cap\", \"Trailing P/E Ratio\", \"Forward P/E Ratio\", \n",
    "     \"Price to Book Ratio\", \"Dividend Yield\", \n",
    "                                         \"Earnings Per Share Forward\", \n",
    "     \"Return on Equity\", \"Debt to Equity Ratio\", \"Free Cash Flow\", \n",
    "                                         \"Revenue Growth\", \"Beta (Volatility)\", \n",
    "     \"Operating Margin\", \"Gross Margin\", \"Price to Sales Ratio\", \n",
    "                                         \"Current Ratio\", \"Quick Ratio\", \n",
    "     \"Return on Assets\", \"Enterprise Value\", \"Enterprise Value to EBITDA\", \n",
    "                                         \"PEG Ratio\", \n",
    "     \"Book Value Per Share\"]].applymap(np.isinf)\n",
    "\n",
    "# Print out any rows with infinite values\n",
    "print(df_stocks_data_merged[infinity_values.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "33031f75-7359-4a33-a58f-dedfbc8907f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Symbol                        11964\n",
       "Name                          11964\n",
       "Market Cap                    11964\n",
       "Trailing P/E Ratio            11964\n",
       "Forward P/E Ratio             11964\n",
       "Price to Book Ratio           11964\n",
       "Dividend Yield                11964\n",
       "Earnings Per Share Forward    11964\n",
       "Return on Equity              11964\n",
       "Debt to Equity Ratio          11964\n",
       "Free Cash Flow                11964\n",
       "Revenue Growth                11964\n",
       "Beta (Volatility)             11964\n",
       "Operating Margin              11964\n",
       "Gross Margin                  11964\n",
       "Price to Sales Ratio          11964\n",
       "Current Ratio                 11964\n",
       "Quick Ratio                   11964\n",
       "Return on Assets              11964\n",
       "Enterprise Value              11964\n",
       "Enterprise Value to EBITDA    11964\n",
       "PEG Ratio                     11964\n",
       "Book Value Per Share          11964\n",
       "Pays Dividend                 11964\n",
       "Earnings Outcome              11964\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all infinite values the median column values\n",
    "\n",
    "columns_with_inf = ['Trailing P/E Ratio', 'Forward P/E Ratio', 'Price to Sales Ratio']\n",
    "df_stocks_data_merged[columns_with_inf] = df_stocks_data_merged[\n",
    "    columns_with_inf].replace([np.inf, -np.inf], np.nan)\n",
    "df_stocks_data_merged[columns_with_inf] = df_stocks_data_merged[\n",
    "    columns_with_inf].fillna(df_stocks_data_merged[columns_with_inf].median())\n",
    "df_stocks_data_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20c47fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Trailing P/E Ratio</th>\n",
       "      <th>Forward P/E Ratio</th>\n",
       "      <th>Price to Book Ratio</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Earnings Per Share Forward</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Debt to Equity Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Price to Sales Ratio</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Return on Assets</th>\n",
       "      <th>Enterprise Value</th>\n",
       "      <th>Enterprise Value to EBITDA</th>\n",
       "      <th>PEG Ratio</th>\n",
       "      <th>Book Value Per Share</th>\n",
       "      <th>Pays Dividend</th>\n",
       "      <th>Earnings Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>26.156192</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>2.006386</td>\n",
       "      <td>-0.351307</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>-0.276589</td>\n",
       "      <td>-0.226634</td>\n",
       "      <td>1.220011</td>\n",
       "      <td>1.976192</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.033573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>26.156192</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>2.006386</td>\n",
       "      <td>-0.351307</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>-0.276589</td>\n",
       "      <td>-0.226634</td>\n",
       "      <td>1.220011</td>\n",
       "      <td>1.976192</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.033573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>26.156192</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>2.006386</td>\n",
       "      <td>-0.351307</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>-0.276589</td>\n",
       "      <td>-0.226634</td>\n",
       "      <td>1.220011</td>\n",
       "      <td>1.976192</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.033573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>26.156192</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>2.006386</td>\n",
       "      <td>-0.351307</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>0.108846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>-0.276589</td>\n",
       "      <td>-0.226634</td>\n",
       "      <td>1.220011</td>\n",
       "      <td>1.976192</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.033573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>25.493544</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.195750</td>\n",
       "      <td>-0.247011</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.129414</td>\n",
       "      <td>-0.173046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>-0.233823</td>\n",
       "      <td>-0.184657</td>\n",
       "      <td>0.862928</td>\n",
       "      <td>1.816486</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>25.493544</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.195750</td>\n",
       "      <td>-0.247011</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.129414</td>\n",
       "      <td>-0.173046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>-0.233823</td>\n",
       "      <td>-0.184657</td>\n",
       "      <td>0.862928</td>\n",
       "      <td>1.816486</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>25.493544</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.195750</td>\n",
       "      <td>-0.247011</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.129414</td>\n",
       "      <td>-0.173046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>-0.233823</td>\n",
       "      <td>-0.184657</td>\n",
       "      <td>0.862928</td>\n",
       "      <td>1.816486</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>25.493544</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.195750</td>\n",
       "      <td>-0.247011</td>\n",
       "      <td>0.887650</td>\n",
       "      <td>0.129414</td>\n",
       "      <td>-0.173046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>-0.233823</td>\n",
       "      <td>-0.184657</td>\n",
       "      <td>0.862928</td>\n",
       "      <td>1.816486</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.020314</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>22.759833</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>0.060271</td>\n",
       "      <td>2.057262</td>\n",
       "      <td>-0.477075</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>-0.199460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>0.058645</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>2.976016</td>\n",
       "      <td>2.037560</td>\n",
       "      <td>0.066665</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.034104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>NVIDIA Corporation Common Stock</td>\n",
       "      <td>22.759833</td>\n",
       "      <td>0.461891</td>\n",
       "      <td>0.060271</td>\n",
       "      <td>2.057262</td>\n",
       "      <td>-0.477075</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>0.331013</td>\n",
       "      <td>-0.199460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009403</td>\n",
       "      <td>0.058645</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>2.976016</td>\n",
       "      <td>2.037560</td>\n",
       "      <td>0.066665</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>-0.034104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                                Name  Market Cap  Trailing P/E Ratio  \\\n",
       "0   AAPL             Apple Inc. Common Stock   26.156192            0.052293   \n",
       "1   AAPL             Apple Inc. Common Stock   26.156192            0.052293   \n",
       "2   AAPL             Apple Inc. Common Stock   26.156192            0.052293   \n",
       "3   AAPL             Apple Inc. Common Stock   26.156192            0.052293   \n",
       "4   MSFT  Microsoft Corporation Common Stock   25.493544            0.021758   \n",
       "5   MSFT  Microsoft Corporation Common Stock   25.493544            0.021758   \n",
       "6   MSFT  Microsoft Corporation Common Stock   25.493544            0.021758   \n",
       "7   MSFT  Microsoft Corporation Common Stock   25.493544            0.021758   \n",
       "8   NVDA     NVIDIA Corporation Common Stock   22.759833            0.461891   \n",
       "9   NVDA     NVIDIA Corporation Common Stock   22.759833            0.461891   \n",
       "\n",
       "   Forward P/E Ratio  Price to Book Ratio  Dividend Yield  \\\n",
       "0           0.042191             2.006386       -0.351307   \n",
       "1           0.042191             2.006386       -0.351307   \n",
       "2           0.042191             2.006386       -0.351307   \n",
       "3           0.042191             2.006386       -0.351307   \n",
       "4           0.044056             0.195750       -0.247011   \n",
       "5           0.044056             0.195750       -0.247011   \n",
       "6           0.044056             0.195750       -0.247011   \n",
       "7           0.044056             0.195750       -0.247011   \n",
       "8           0.060271             2.057262       -0.477075   \n",
       "9           0.060271             2.057262       -0.477075   \n",
       "\n",
       "   Earnings Per Share Forward  Return on Equity  Debt to Equity Ratio  ...  \\\n",
       "0                    0.372867          0.407950              0.108846  ...   \n",
       "1                    0.372867          0.407950              0.108846  ...   \n",
       "2                    0.372867          0.407950              0.108846  ...   \n",
       "3                    0.372867          0.407950              0.108846  ...   \n",
       "4                    0.887650          0.129414             -0.173046  ...   \n",
       "5                    0.887650          0.129414             -0.173046  ...   \n",
       "6                    0.887650          0.129414             -0.173046  ...   \n",
       "7                    0.887650          0.129414             -0.173046  ...   \n",
       "8                    0.048026          0.331013             -0.199460  ...   \n",
       "9                    0.048026          0.331013             -0.199460  ...   \n",
       "\n",
       "   Price to Sales Ratio  Current Ratio  Quick Ratio  Return on Assets  \\\n",
       "0             -0.059645      -0.276589    -0.226634          1.220011   \n",
       "1             -0.059645      -0.276589    -0.226634          1.220011   \n",
       "2             -0.059645      -0.276589    -0.226634          1.220011   \n",
       "3             -0.059645      -0.276589    -0.226634          1.220011   \n",
       "4             -0.053199      -0.233823    -0.184657          0.862928   \n",
       "5             -0.053199      -0.233823    -0.184657          0.862928   \n",
       "6             -0.053199      -0.233823    -0.184657          0.862928   \n",
       "7             -0.053199      -0.233823    -0.184657          0.862928   \n",
       "8             -0.009403       0.058645     0.050335          2.976016   \n",
       "9             -0.009403       0.058645     0.050335          2.976016   \n",
       "\n",
       "   Enterprise Value  Enterprise Value to EBITDA  PEG Ratio  \\\n",
       "0          1.976192                    0.007904  -0.000231   \n",
       "1          1.976192                    0.007904  -0.000231   \n",
       "2          1.976192                    0.007904  -0.000231   \n",
       "3          1.976192                    0.007904  -0.000231   \n",
       "4          1.816486                    0.003603  -0.000231   \n",
       "5          1.816486                    0.003603  -0.000231   \n",
       "6          1.816486                    0.003603  -0.000231   \n",
       "7          1.816486                    0.003603  -0.000231   \n",
       "8          2.037560                    0.066665  -0.000231   \n",
       "9          2.037560                    0.066665  -0.000231   \n",
       "\n",
       "   Book Value Per Share  Pays Dividend  Earnings Outcome  \n",
       "0             -0.033573              1                 1  \n",
       "1             -0.033573              1                 1  \n",
       "2             -0.033573              1                 1  \n",
       "3             -0.033573              1                 1  \n",
       "4             -0.020314              1                 1  \n",
       "5             -0.020314              1                 1  \n",
       "6             -0.020314              1                 1  \n",
       "7             -0.020314              1                 1  \n",
       "8             -0.034104              1                 1  \n",
       "9             -0.034104              1                 1  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Module to standardize numerical data by scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Used to perform scaling transformation on the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Use StandardScaler() to standardize the values of each column \n",
    "df_merged_stocks_data_scaled = df_stocks_data_merged.copy()\n",
    "df_merged_stocks_data_scaled[[\"Market Cap\", \"Trailing P/E Ratio\", \n",
    "                              \"Forward P/E Ratio\", \"Price to Book Ratio\", \n",
    "                              \"Dividend Yield\", \"Earnings Per Share Forward\", \n",
    "                              \"Return on Equity\", \"Debt to Equity Ratio\", \n",
    "                              \"Free Cash Flow\", \"Revenue Growth\", \n",
    "                              \"Beta (Volatility)\", \"Operating Margin\", \n",
    "                              \"Gross Margin\", \"Price to Sales Ratio\", \n",
    "                              \"Current Ratio\", \"Quick Ratio\", \"Return on Assets\", \n",
    "                              \"Enterprise Value\", \"Enterprise Value to EBITDA\", \n",
    "                              \"PEG Ratio\", \"Book Value Per Share\"]]= scaler.fit_transform(\n",
    "        df_stocks_data_merged[[\"Market Cap\", \"Trailing P/E Ratio\", \n",
    "                               \"Forward P/E Ratio\", \"Price to Book Ratio\", \n",
    "                               \"Dividend Yield\", \"Earnings Per Share Forward\", \n",
    "                               \"Return on Equity\", \"Debt to Equity Ratio\", \n",
    "                               \"Free Cash Flow\", \"Revenue Growth\", \n",
    "                               \"Beta (Volatility)\", \"Operating Margin\", \n",
    "                               \"Gross Margin\", \"Price to Sales Ratio\", \n",
    "                               \"Current Ratio\", \"Quick Ratio\", \n",
    "                               \"Return on Assets\", \"Enterprise Value\", \n",
    "                               \"Enterprise Value to EBITDA\", \"PEG Ratio\", \n",
    "                               \"Book Value Per Share\"]]\n",
    ")\n",
    "\n",
    "df_merged_stocks_data_scaled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbe15e",
   "metadata": {},
   "source": [
    "## Baseline Model: Logisitic Regression and Decision Tree\n",
    "In order to establish a point of reference for evaluating the effectiveness of more complex models, we need to create a baseline model. A baseline model will help us understand whether more advanced models provide meaningful improvements, if the data needs more preprocessing, or if the problem is too challenging for predictive modeling and more or different data is required. \n",
    "\n",
    "To create this baseline model, we're going to utilize two different modeling approaches: logistic regression and decision trees. Whichever of these two models is a better and more balanced predictor of the outcome of a target variable is the one we will choose as the baseline. Logistic regression is a linear classification algorithm that predicts probabilities for binary outcomes. It is easily interpretable as it produces coefficients for each feature, indicating their influence on the prediction. A decision tree is a non-linear classification algorithm that splits data based on feature values, creating a tree-like structure of decisions. It captures complex relationships between variables and will handle non-linearity better than logistic regression. We are not yet sure whether our data is linear or non-linear, so we need to try both algorithms to see which better fits the data. \n",
    "\n",
    "One of the first steps in creating a predictive model, after preprocessing, is splitting the data into training and testing sets. The data is usually split 70-80% for training and 20-30% for testing and we do this because if we train the model purely on all available data, it may perform exceptionally well but perform very poorly with new, unseen data, which would indicate overfitting. We use the training set to fit the model and capture the patterns and relationships of the given data. The testing set is used to evaluate the model's performance on unseen data to simulate real-world predictions. \n",
    "\n",
    "Upon splitting the data into training and test sets and running both models, we will use the following metrics to evaluate the models ability to predict the target variable: Accuracy, Precision, Recall, F1 Score, and AUC.\n",
    "\n",
    "Accuracy\n",
    "* = (Number of Correct Predictions / Total Number of Predictions)\n",
    "\n",
    "* The proportion of correct predictions out of all predictions. Very useful for balanced datasets (equal number of samples in each class), but can be misleading for imbalanced datasets. \n",
    "\n",
    "Precision\n",
    "* = (True Positives / (True Positives + False Positives))\n",
    "\n",
    "* The proportion of true positive predictions out of all positive predictions. It is a measure of how many of hte predicted positives outcomes are actually positive. \n",
    "\n",
    "Recall (Sensitivity)\n",
    "* = (True Positives / (True Positives + False Negatives))\n",
    "\n",
    "* The proportion of true positives out of all actual positive cases. It assesses the model's ability to detect all positive instances. \n",
    "\n",
    "F1 Score\n",
    "* = 2 x ((Precision x Recall) / (Precision + Recall))\n",
    "\n",
    "* Calculates the harmonic mean of Precision and Recall by comining them into a single metric. It provides a balanced measure than accounts for both false positives and false negatives, making it useful for imbalanced datasets. \n",
    "\n",
    "AUC (Area Under ROC Curve)\n",
    "* Represents the probability that a randomly chosen positive instance is ranked higher by the model than a randomly chosen negative instance.A higher AUC indicates a better model at distinguishing between positive and negative cases, with value of 1 representing a perfect model and a value of 0.5 representing a model with no predictive power (equivalent to random guessing). \n",
    "\n",
    "After evaluating the model's performance metrics, we'll create a confusion matrix, which is a table that shows all true positives, false positives, true negatives, and false negatives of a classification model. It helps visualize the model's performance across differnet prediction categories and can help in adjusting thresholds for models like logistic regression to balance precision and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e8b2e-721d-4383-8d88-232d4c0e2cb6",
   "metadata": {},
   "source": [
    "## Precision\n",
    "This service will be providing stocks which have a high probability of beating their earnings report and therefore increasing in value. In this circumstance, a stock beating its' EPS is positive and a stock not beating it's EPS is negative. Callaghan Investments is much more concerned with correctly choosing stocks which do beat it's next earnings report (True Positive), rather than missing out on stocks who end up beating their estimated EPS (False Negative). The worst possible scenario in this case, is prediciting that a stock will beat it's estimated EPS and it does not (False Positive). Because of this, the main metric we are focusing on is Precision. Precision tells us how many positive outcomes are actually positive, or in other words, how many stocks predicted to beat their estimated EPS actually beat their estimated EPS. We are much less focused on Recall and Accuracy because we are not trying to predict if a stock will not beat its' earnings report and are not as concerned with missing out on a stock which does beat it's earnings report. In summation, we will be choosing the model with the highest precision and if there is a tie, we will take F1 score into consideration as that combines Precision and Recall into a single metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5915cf9",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline Model\n",
    "Below, we will run logistic regression on our model and evaluate the output of metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ac9d7ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.12      0.20       920\n",
      "           1       0.63      0.93      0.75      1473\n",
      "\n",
      "    accuracy                           0.62      2393\n",
      "   macro avg       0.58      0.53      0.48      2393\n",
      "weighted avg       0.59      0.62      0.54      2393\n",
      "\n",
      "ROC AUC: 0.6409180465775258\n"
     ]
    }
   ],
   "source": [
    "# Import train-test split utility\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import evaluation metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Define features (x) and target (y)\n",
    "\n",
    "# Drop non-feature columns\n",
    "x = df_merged_stocks_data_scaled.drop(columns=[\"Earnings Outcome\", \"Symbol\", \n",
    "                                               \"Name\"])\n",
    "\n",
    "# Target Variable\n",
    "y = df_merged_stocks_data_scaled[\"Earnings Outcome\"] \n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate model and print metrics\n",
    "y_pred = log_reg.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, log_reg.predict_proba(x_test)[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a446f8a",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline Model: Confusion Matrix\n",
    "To help evaluate our logistic regression model, we'll output a confusion matrix which shows the True Positives, True Negatives, False Positives, and False Negatives. Along with this will be our performance metrics, Accuracy, Precision, Recall, F1 Score, and ROC AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76257efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n",
      "Precision: 0.63\n",
      "Recall: 0.93\n",
      "F1 Score: 0.75\n",
      "ROC AUC: 0.64\n",
      "Confusion Matrix:\n",
      " [[ 113  807]\n",
      " [  97 1376]]\n"
     ]
    }
   ],
   "source": [
    "# Import Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    ", f1_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "# Assuming 1 corresponds to 'Beat'\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1) # Calculate recall\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1) # Calculate F1 Score\n",
    "# Calculate ROC AUC Score\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, log_reg.predict_proba(x_test)[:, 1]) \n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf42db",
   "metadata": {},
   "source": [
    "## Logistic Regression Metrics Evaluation\n",
    "\n",
    "### Accuracy\n",
    "* 0.62\n",
    "* The model correctly predicted 62% of the test samples. \n",
    "* This is a pretty low to moderate accuracy level, but since we are not trying to predict both classes equally, we are not as concerned about accuracy. On top of that, our dataset is imbalanced, which means Accuracy is not a very good metric to use. \n",
    "\n",
    "### Precision\n",
    "* 0.63\n",
    "* Out of all the times the model predicted \"Beat\" (class 1), its' predictions were correct 63% of the time \n",
    "* This precision value is moderate and there is still room for improvement. We want to minimize false positives. \n",
    "\n",
    "### Recall\n",
    "* 0.93\n",
    "* The model correctly predicted 93% of the actual \"Beat\" cases. \n",
    "* High recall demonstrates that the model is model is very sensitive to identifying true positive cases, but it also means it's capturing many false positives, which is what we are trying to avoid.\n",
    "\n",
    "### F1 Score\n",
    "* 0.75\n",
    "* This is a moderate to high F1 Score, but it is being inflated by the very high recall. \n",
    "\n",
    "### ROC AUC\n",
    "* 0.64\n",
    "* This is a moderate ROC AUC score and indicates the model is slightly better at distinguishing the classes than random guessing.\n",
    "\n",
    "### Evaluation Summary\n",
    "* This model has strong recall, however it comes at the cost of precision, which is the metric we want to maximize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f23dd1",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Now we will create another baseline model, using a decision tree. We'll evaluate and compare the outputs of both models in order to choose a baseline to move forward with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "094b7d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.59      0.55       920\n",
      "           1       0.72      0.66      0.69      1473\n",
      "\n",
      "    accuracy                           0.63      2393\n",
      "   macro avg       0.62      0.62      0.62      2393\n",
      "weighted avg       0.64      0.63      0.64      2393\n",
      "\n",
      "ROC AUC: 0.6659612149118923\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# x and y already defined above\n",
    "# Initialize and train the Decision Tree Classifier\n",
    "# Set a random state for reproducibility\n",
    "tree = DecisionTreeClassifier(random_state=42) \n",
    "tree.fit(x_train, y_train) # Fit the model using the training data\n",
    "\n",
    "# Evaluate model on the test data\n",
    "y_pred_tree = tree.predict(x_test) # Generate predictions on the test set\n",
    "\n",
    "# Print classification metrics\n",
    "# Display precision, recall, F1 score, and accuracy\n",
    "print(classification_report(y_test, y_pred_tree)) \n",
    "# Calculate and display ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, tree.predict_proba(x_test)[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6aa8d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Precision: 0.72\n",
      "Recall: 0.66\n",
      "F1 Score: 0.69\n",
      "ROC AUC: 0.67\n",
      "Confusion Matrix:\n",
      " [[546 374]\n",
      " [506 967]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    ", f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predict on the test data using the decision tree model\n",
    "y_pred_tree = tree.predict(x_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, F1-score, and AUC (ROC)\n",
    "accuracy = accuracy_score(y_test, y_pred_tree)\n",
    "# Assuming 1 corresponds to 'Beat'\n",
    "precision = precision_score(y_test, y_pred_tree, pos_label=1)  \n",
    "recall = recall_score(y_test, y_pred_tree, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_tree, pos_label=1)\n",
    "\n",
    "# Decision trees can also give probabilities, so we use predict_proba for ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, tree.predict_proba(x_test)[:, 1])\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427747c",
   "metadata": {},
   "source": [
    "## Decision Tree Metrics Evaluation (UPDATE 11/12/2024: THIS NEEDS TO BE REDONE TO REFLECT THE NEWLY EVALUATED MODE. BASELINE DECISION TREE MODEL WITHOUT CLASS BALANCING)\n",
    "\n",
    "### Accuracy\n",
    "* 0.63\n",
    "* The decision tree model correctly predicted 63% of test samples overall.\n",
    "* This is a moderate accuracy score, but may be misleading because of the class imbalance.\n",
    "\n",
    "### Precision\n",
    "* 0.72\n",
    "* When the decision tree model predicted \"Beat, it was correct 72% of the time. \n",
    "* moderate to good Precision score, which indicates the model is reliable when prediciting \"Beat\". \n",
    "\n",
    "### Recall\n",
    "* 0.66\n",
    "* The decision tree model correctly identified 90% of actual \"Beat\" cases.\n",
    "* This is a moderate recall score.\n",
    "\n",
    "### F1 Score\n",
    "* 0.69\n",
    "* This is a moderate F1 Score and shows the model performs decent in balancing both Precision and Recall for the \"Beat\" class. \n",
    "\n",
    "### ROC AUC\n",
    "* 0.65\n",
    "* This is a moderate score and indicates that the decision tree model has some ability to descriminate between the two classes, \"Beat\" and \"Not Beat\". \n",
    "* The model performs slightly better than random guessing.\n",
    "\n",
    "### Evaluation Summary\n",
    "* The decision tree has much precision (0.72) than the our baseline logistic regression model (0.63) and therefore performs better in our context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e80c7",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline Vs. Decision Tree Baseline \n",
    "\n",
    "Since Precision is our most important indicator, we are going to use the Decision Tree as our baseline model. Logistic Regression had a lower Precision score and a very high Recall, which means that we would have to do more work in order to lower the Recall in order to increase Precision. The Decision Tree model already improves Precision by lowering Recall, so it is a better baseline model in this context. On top of this, the F1 Score was very similar and it had a more favorable Confusion Matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd8829-3a3b-4804-8f6c-e580753ae136",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset: SMOTE and SMOTEEN. \n",
    "To try and handle our class imbalance between class 0 (not beating EPS) and class 1 (beating EPS), we going to apply a data preprocessing technique called SMOTE (Synthetic Minority Oversampling Technique). It addresses the class imbalance by creating synthetic examples for the minority class instead of simply duplicating existing examples. We do this to reduce bias in our model predictions and increase the potential of pattern recognition in the minority class. If it does not lead to significant improvement over our baseline model, then we will remove SMOTE to prevent overcomplicating our model with unhelpful processing. \n",
    "\n",
    "After trying SMOTE, we are also going to try SMOTEEN. SMOTEEN combines SMOTE with an editing technique called Edited Nearest Neighbors (ENN), which takes SMOTE and removes noisy or misclassified instances by checking each instance's nearest neighbors and removing instances that do not agree with the majority of their neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "891c027e-2dc3-47b1-9e04-3f4fa6f52dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Precision: 0.72\n",
      "Recall: 0.65\n",
      "F1 Score: 0.68\n",
      "ROC AUC: 0.65\n",
      "Confusion Matrix:\n",
      " [[556 371]\n",
      " [513 953]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.60      0.56       927\n",
      "           1       0.72      0.65      0.68      1466\n",
      "\n",
      "    accuracy                           0.63      2393\n",
      "   macro avg       0.62      0.62      0.62      2393\n",
      "weighted avg       0.64      0.63      0.63      2393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To deal with the imbalance in class weights, we are going to try applying SMOTE\n",
    "# to see if it improves our model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ", confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Initialize and fit the Decision Tree model\n",
    "tree_smote = DecisionTreeClassifier(random_state=42)\n",
    "tree_smote.fit(x_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test data using the SMOTE-enhanced decision tree model\n",
    "y_pred_tree_smote = tree_smote.predict(x_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_tree_smote)\n",
    "# Assuming 1 corresponds to 'Beat'\n",
    "precision_smote = precision_score(y_test, y_pred_tree_smote, pos_label=1) \n",
    "recall_smote = recall_score(y_test, y_pred_tree_smote, pos_label=1)\n",
    "f1_smote = f1_score(y_test, y_pred_tree_smote, pos_label=1)\n",
    "roc_auc_smote = roc_auc_score(y_test, tree_smote.predict_proba(x_test)[:, 1])\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_smote:.2f}\")\n",
    "print(f\"Precision: {precision_smote:.2f}\")\n",
    "print(f\"Recall: {recall_smote:.2f}\")\n",
    "print(f\"F1 Score: {f1_smote:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc_smote:.2f}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "conf_matrix_smote = confusion_matrix(y_test, y_pred_tree_smote)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_smote)\n",
    "\n",
    "# Additional detailed classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_tree_smote))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72579fc-f7b8-4fcb-98ff-b4025d2cf2c7",
   "metadata": {},
   "source": [
    "## Model Evaluation: Baseline Decision Tree vs. Decision Tree with SMOTE\n",
    "Going forward, we are only going to evaluate the models based off Precision, which we are trying to maximize. On top of this, we may also look at the number of True Positives, as maximizing precision too much may lead to too much of a reduction in True Positives, meaning we would have to loosen up the restrictions a little bit in order to have enough stocks for a portfolio. \n",
    "\n",
    "### Baseline Decision Tree Precision: 0.72\n",
    "\n",
    "### Decision Tree with SMOTE Precision: 0.72\n",
    "\n",
    "With the addition of SMOTE, there was no change in precision. On top of this, the amount of True Positives and False positives remained relativley the same. Because we don't want to add unnecessary complexity to our model, we are going to refrain from adding SMOTE and stick to the baseline Decision Tree Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "84e1090a-1604-49a9-8d7b-194acb299e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with SMOTEEN Metrics:\n",
      "Accuracy: 0.62\n",
      "Precision: 0.74\n",
      "Recall: 0.59\n",
      "F1 Score: 0.65\n",
      "ROC AUC: 0.63\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.68      0.58       927\n",
      "           1       0.74      0.59      0.65      1466\n",
      "\n",
      "    accuracy                           0.62      2393\n",
      "   macro avg       0.62      0.63      0.62      2393\n",
      "weighted avg       0.65      0.62      0.63      2393\n",
      "\n",
      "Confusion Matrix:\n",
      " [[626 301]\n",
      " [606 860]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Decision Tree Classifier\n",
    "tree_smoteen = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Decision Tree\n",
    "pipeline_smoteen = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "y_pred_smoteen = pipeline_smoteen.predict(x_test)\n",
    "\n",
    "# Predict probabilities for ROC AUC\n",
    "y_pred_proba_smoteen = pipeline_smoteen.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_smoteen)\n",
    "precision = precision_score(y_test, y_pred_smoteen, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_smoteen, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_smoteen, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_smoteen)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Decision Tree with SMOTEEN Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smoteen))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_smoteen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc3718-90f5-46f1-9642-1825c7b8b3ed",
   "metadata": {},
   "source": [
    "## Model Evaluation: Baseline Decision Tree vs. Decision Tree with SMOTEEN\n",
    "\n",
    "### Basline Decision Tree Precision: 0.72\n",
    "\n",
    "### Decision Tree with SMOTEEN Precision: 0.74\n",
    "\n",
    "Adding SMOTEEN lead to an increase in Precision of 0.02. This is a step in the right direction and because of this, we are going to keep SMOTEEN in our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f609b05-a9de-412c-a1a8-cc52b35f400b",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "Gradient boosting is an ensemble machine learning technique which creates multiple decision trees sequentially in order to create a stronger, more accurate model. It creates a decision tree, calculates the residuals, trains a new model to predict these residuals, those predictions are combined with the previous models predictions, and it iterates over this until a predetermined level of error is reached. Gradient boosting reduces bias and variance while adding accuracy to the predictions. For these reasons, we are going to try adding it to our baseline decision tree model and evaluate its' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9dd0f6f1-3003-493c-be44-bae1b6a898ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.37      0.45       927\n",
      "           1       0.67      0.82      0.74      1466\n",
      "\n",
      "    accuracy                           0.65      2393\n",
      "   macro avg       0.62      0.60      0.59      2393\n",
      "weighted avg       0.63      0.65      0.63      2393\n",
      "\n",
      "Accuracy: 0.65\n",
      "Precision: 0.67\n",
      "Recall: 0.82\n",
      "F1 Score: 0.74\n",
      "ROC AUC: 0.68\n",
      "Confusion Matrix:\n",
      " [[ 342  585]\n",
      " [ 261 1205]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    ", f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the Gradient Boosting model\n",
    "tree_gradient_boost = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Fit the Gradient Boosting model to the training data\n",
    "tree_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_boost = tree_gradient_boost.predict(x_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"\\nGradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_boost))\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_boost)\n",
    "precision = precision_score(y_test, y_pred_boost, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_boost, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_boost, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, tree_gradient_boost.predict_proba(x_test)[:, 1])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_boost))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de8ea3-752c-496a-89b9-63dabbc21b5b",
   "metadata": {},
   "source": [
    "## Model Evaluation: Baseline Decision Tree with SMOTEEN vs. Baseline Decision Tree with Gradient Boost\n",
    "\n",
    "### Baseline Decision Tree with SMOTEEN Precision: 0.74\n",
    "\n",
    "### Baseline Decision Tree with Gradient Boost Precision: 0.67\n",
    "\n",
    "Adding gradient boosting to my baseline decision tree model yielded a Precision value of 0.67, which is lower than the Precision value for my baseline decision. tree with SMOTEEN added. For this reason, I am going to move forward with my baseline decision tree model with SMOTEEN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294ff3d-c8f3-4084-80b4-03f115883c04",
   "metadata": {},
   "source": [
    "## Decision Tree with Gradient Boosting and SMOTEEN\n",
    "For methodolical testing, I tried combining gradient boosting and SMOTEEN to evaluate its Precision power. This is to test whether combining the strengths of SMOTEEN (better handling of imbalance) along with Gradient Boosting (ensemble learning to reduce bias and variance) leads to a stronger model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "60b944b6-dada-48c1-9587-5468fde20ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting with SMOTEEN Metrics:\n",
      "Accuracy: 0.63\n",
      "Precision: 0.74\n",
      "Recall: 0.62\n",
      "F1 Score: 0.67\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58       927\n",
      "           1       0.74      0.62      0.67      1466\n",
      "\n",
      "    accuracy                           0.63      2393\n",
      "   macro avg       0.63      0.63      0.62      2393\n",
      "weighted avg       0.65      0.63      0.63      2393\n",
      "\n",
      "Confusion Matrix:\n",
      " [[603 324]\n",
      " [563 903]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=1,          # Fraction of samples used for fitting each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "y_pred_smoteen_gradient_boost = pipeline_smoteen_gradient_boost.predict(x_test)\n",
    "\n",
    "# Predict probabilities for ROC AUC\n",
    "y_pred_proba_smoteen_gradient_boost = pipeline_smoteen_gradient_boost.predict_proba(\n",
    "    x_test)[:, 1]\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_smoteen_gradient_boost)\n",
    "precision = precision_score(y_test, y_pred_smoteen_gradient_boost, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_smoteen_gradient_boost, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_smoteen_gradient_boost, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_smoteen_gradient_boost)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Gradient Boosting with SMOTEEN Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smoteen_gradient_boost))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_smoteen_gradient_boost))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd026ef5-ae45-4a7a-9fe9-c89c4e03cf0b",
   "metadata": {},
   "source": [
    "## Baseline Decision Tree with SMOTEEN vs. Baseline Decision Tree with SMOTEEN and Gradient Boosting\n",
    "\n",
    "### Baseline Decision Tree with SMOTEEN Precision: 0.74\n",
    "\n",
    "### Baseline Decision Tree with SMOTEEN and Gradient Boost Precision: 0.74\n",
    "\n",
    "There was no increase in the Precision value by adding Gradient boosting to our baseline decision tree model with SMOTEEN, however the F1 score and True Positives increased in the decision tree model with SMOTEEN and gradient boosting (0.67 and 903 respectivley) vs our decision tree model with just SMOTEEN (0.65 and 860 respectivley). In an attempt to raise our Precision value, we are going to take our baseline decision tree model with SMOTEEN and Gradient boosting and increase the threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e0a708-5964-490e-bc7d-62a11f8b09a1",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Threshold Adjustment\n",
    "With the goal of increasing Precisioon, we are purposley goiong to make our model more conservative and increase the threshold probability of the model predicting class 1 (a stock beating it's EPS estimate). The standard threshold is 0.5, which means if the predicted probability of a stock beating its' earnings report, it will be classified as class 1 (AKA the stock will be predicted to beat it's earnings rerport). If its' predicted probability is less than 0.5, it will be classified as class 0 (AKA the stock is predicted to not beat its' earnings report). By raising the threshold to 0.9, the model will only classify a stock as class 1 (Beating its' EPS estimate) if the probability is greater than 90% of doing so. This should increase precision and decrease recall, but since we only care about precision, we are willing to sacrifice our recall. This is desirable because we want to be sure that when we recommend stocks to our investors, the model is only predicting stocks with a very high probability of beating their EPS estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b84c68a1-6363-46b1-8280-3c853eefaf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting with SMOTEEN Metrics (Adjusted Threshold):\n",
      "Accuracy: 0.46\n",
      "Precision: 0.82\n",
      "Recall: 0.14\n",
      "F1 Score: 0.24\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (Adjusted Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.95      0.58       927\n",
      "           1       0.82      0.14      0.24      1466\n",
      "\n",
      "    accuracy                           0.46      2393\n",
      "   macro avg       0.62      0.55      0.41      2393\n",
      "weighted avg       0.66      0.46      0.37      2393\n",
      "\n",
      "Confusion Matrix (Adjusted Threshold):\n",
      " [[ 881   46]\n",
      " [1255  211]]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=1,          # Fraction of samples used for fitting each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "precision = precision_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "# Use unadjusted probabilities for ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba) \n",
    "\n",
    "# Print the evaluation maetrics\n",
    "print(\"Gradient Boosting with SMOTEEN Metrics (Adjusted Threshold):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (Adjusted Threshold):\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (Adjusted Threshold):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ec0b5-d3af-4196-890e-4a82b58065bf",
   "metadata": {},
   "source": [
    "## Model Evaluation: Baseline Decision Tree with SMOTEEN, Gradient Boosting, and Threshold Adjustement\n",
    "\n",
    "### Baseline Decision Tree with SMOTEEN, Gradient Boosting, and Threshold Adjustement \n",
    "* Precision: 0.82\n",
    "\n",
    "Through adjusting threshold to 0.9, we had a dramatic increase in our Precision value from 0.74 to 0.84. Through this, we can see how we sacrificed our Recall, as it dropped from a value of 0.63 to 0.16. Our True Positives also had a drop from 919 to 228, but our False Positives are now at 44 instead of 325. Although we had a big drop in True Positives and an inevitable increase in False Negatives, we can be sure that the stocks we recommend to our investors have a much higher liklihood of beating their EPS estimates, while still giving investors an ample number of stocks to choose from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8846a2e0-bb54-46da-b770-d77ca502abf4",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Subsample\n",
    "Subsample is a hyperparameter that controls the proportion of training data used to fit each individual tree in the ensemble. When the subsample is set to a value less than 1, the algorithm randomly samples a fraction of the training data before building each tree. The purpose of altering the subsample size is to:\n",
    "* Reduce overfitting: Using a smaller subset of the data, the algorithm is less likely to memorize noise\n",
    "* Increase Robustness: Noisy or outlier data points get averaged out, leading to a more stable model\n",
    "* Improve computational efficiency: Since fewer data points need to be processed, subsampling reduces the computational burden of training each tree\n",
    "\n",
    "The default value for subsample is 1. We are going to try lowering it to 0.9, 0.8, and 0.7 and evaluate the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc82c0a8-a7d3-416b-8599-ec7196fdd637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.9):\n",
      "Accuracy: 0.46\n",
      "Precision: 0.84\n",
      "Recall: 0.16\n",
      "F1 Score: 0.26\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (Subsample = 0.9):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.95      0.58       927\n",
      "           1       0.84      0.16      0.26      1466\n",
      "\n",
      "    accuracy                           0.46      2393\n",
      "   macro avg       0.63      0.55      0.42      2393\n",
      "weighted avg       0.67      0.46      0.39      2393\n",
      "\n",
      "Confusion Matrix (Subsample = 0.9):\n",
      " [[ 883   44]\n",
      " [1238  228]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Decision Tree Model with SMOTEEN and Gradient Boosting: Subsample = 0.9\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=0.9,          # Fraction of samples used for fitting each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_subsample9 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_subsample9)\n",
    "precision = precision_score(y_test, y_pred_subsample9 , pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_subsample9 , pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_subsample9 , pos_label=1)\n",
    "# Use unadjusted probabilities for ROC AUC\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba) \n",
    "# Print the evaluation maetrics\n",
    "print(\"Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.9):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (Subsample = 0.9):\")\n",
    "print(classification_report(y_test, y_pred_subsample9))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (Subsample = 0.9):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_subsample9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "905c0eb7-f7c8-4bee-a970-328f47d459fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.8):\n",
      "Accuracy: 0.46\n",
      "Precision: 0.86\n",
      "Recall: 0.14\n",
      "F1 Score: 0.24\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (Subsample = 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.96      0.58       927\n",
      "           1       0.86      0.14      0.24      1466\n",
      "\n",
      "    accuracy                           0.46      2393\n",
      "   macro avg       0.64      0.55      0.41      2393\n",
      "weighted avg       0.69      0.46      0.37      2393\n",
      "\n",
      "Confusion Matrix (Subsample = 0.8):\n",
      " [[ 894   33]\n",
      " [1258  208]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Decision Tree Model with SMOTEEN and Gradient Boosting: Subsample = 0.8\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=0.8,          # Fraction of samples used for fitting each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_subsample8 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_subsample8)\n",
    "precision = precision_score(y_test, y_pred_subsample8 , pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_subsample8 , pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_subsample8 , pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  \n",
    "\n",
    "# Print the evaluation maetrics\n",
    "print(\"Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.8):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (Subsample = 0.8):\")\n",
    "print(classification_report(y_test, y_pred_subsample8))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (Subsample = 0.8):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_subsample8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cba33e2f-cf9e-459e-a9fa-fcab0d922861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.7):\n",
      "Accuracy: 0.46\n",
      "Precision: 0.82\n",
      "Recall: 0.15\n",
      "F1 Score: 0.25\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (Subsample = 0.7):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.95      0.58       927\n",
      "           1       0.82      0.15      0.25      1466\n",
      "\n",
      "    accuracy                           0.46      2393\n",
      "   macro avg       0.62      0.55      0.41      2393\n",
      "weighted avg       0.66      0.46      0.38      2393\n",
      "\n",
      "Confusion Matrix (Subsample = 0.7):\n",
      " [[ 878   49]\n",
      " [1247  219]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Decision Tree Model with SMOTEEN and Gradient Boosting: Subsample = 0.7\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=0.7,          # Fraction of samples used for fitting \n",
    "                            # each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_subsample7 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_subsample7)\n",
    "precision = precision_score(y_test, y_pred_subsample7 , pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_subsample7 , pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_subsample7 , pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  \n",
    "\n",
    "# Print the evaluation maetrics\n",
    "print(\"Decision Tree with Gradient Boosting and SMOTEEN Metrics (Subsample = 0.7):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (Subsample = 0.7):\")\n",
    "print(classification_report(y_test, y_pred_subsample7))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (Subsample = 0.7):\\n\", confusion_matrix\n",
    "      (y_test, y_pred_subsample7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e615c89-c76b-4605-8765-9ffa471178fc",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Subsample Evaluation\n",
    "\n",
    "* Subsample = 0.9\n",
    "Adjusting the subsample to 0.9 not only lead to an increase in Precision from 0.82 to 0.84, the number of True Positives also increased from 211 to 228.\n",
    "\n",
    "* Subsample = 0.8\n",
    "A subsample of 0.8 lead to another increase in Precision up to 0.86. The number of True Positives decreased to 208, but that is still a sufficient number of stocks to choose from.\n",
    "\n",
    "* Subsample = 0.7\n",
    "A subsample of 0.7 decreased the Precision from 0.86 back to 0.82, which is what we got when our subsample was at the default value of 1. However, it has a slight edge over the default value because it has 8 more True Positive cases.\n",
    "\n",
    "\n",
    "* Conclusion\n",
    "Judging by the results of adjusting subsample, we are going to modify our model by adjusting the hyperparamter subsample to the value of 0.8. With our goal being maximum Precision power, a subsample of 0.8 brings us closer to that goal while maintaining an abundant basket of stocks to choose from. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1f552-4aa5-4a5f-88bb-366bec8bebef",
   "metadata": {},
   "source": [
    "## Hypeparameter Tuning: n_estimators\n",
    "In gradient boosting algorithms, simple decision trees called 'weak learners' are iteritively created one at a time, with each one fixing the errors of the one before it until a max number of iterations or accuracy threshold is reached. n_estimators is a hyperparamter in gradient boosting algorithms that controls the number of 'weak learners' (decision trees) that are combined to form the final predictor. Increasing n_estimators can raise computational cost and lead to overfitting, which improves the models performance on the training data, but may not translate those results to unseen data. Decreasing n_estimators can reduce overfitting and improve generalization to new data, but may fail to capture all underlying relationships in the data. So far in our model, n_estimators has been set to 100. We are going to try adjusting this to 50 and 150 and evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c891a5f3-ad23-4911-bd7d-026a2e9ec18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Gradient Boosting and SMOTEEN Metrics (n_estimators = 50):\n",
      "Accuracy: 0.43\n",
      "Precision: 0.88\n",
      "Recall: 0.08\n",
      "F1 Score: 0.14\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (n_estimators = 50):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.98      0.57       927\n",
      "           1       0.88      0.08      0.14      1466\n",
      "\n",
      "    accuracy                           0.43      2393\n",
      "   macro avg       0.64      0.53      0.36      2393\n",
      "weighted avg       0.69      0.43      0.31      2393\n",
      "\n",
      "Confusion Matrix (n_estimators = 50):\n",
      " [[ 911   16]\n",
      " [1354  112]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Decision Tree Model with SMOTEEN and \n",
    "# Gradient Boosting: n_estimators = 50\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=50,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=0.8,          # Fraction of samples used for fitting \n",
    "                            # each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_estimators50 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_estimators50)\n",
    "precision = precision_score(y_test, y_pred_estimators50 , pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_estimators50 , pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_estimators50 , pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  \n",
    "# Print the evaluation maetrics\n",
    "print(\"Decision Tree with Gradient Boosting and SMOTEEN Metrics (n_estimators = 50):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (n_estimators = 50):\")\n",
    "print(classification_report(y_test, y_pred_estimators50))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (n_estimators = 50):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_estimators50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04a49597-681f-4178-ae35-7af00968a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Gradient Boosting and SMOTEEN Metrics (n_estimators = 150):\n",
      "Accuracy: 0.47\n",
      "Precision: 0.83\n",
      "Recall: 0.18\n",
      "F1 Score: 0.29\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Classification Report (n_estimators = 150):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.94      0.58       927\n",
      "           1       0.83      0.18      0.29      1466\n",
      "\n",
      "    accuracy                           0.47      2393\n",
      "   macro avg       0.63      0.56      0.44      2393\n",
      "weighted avg       0.67      0.47      0.40      2393\n",
      "\n",
      "Confusion Matrix (n_estimators = 150):\n",
      " [[ 875   52]\n",
      " [1208  258]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline Decision Tree Model with SMOTEEN and \n",
    "# Gradient Boosting: n_estimators = 150\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    confusion_matrix, classification_report, precision_recall_curve\n",
    ")\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Define SMOTEEN for handling class imbalance\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "\n",
    "# Define the Gradient Boosting Classifier with hyperparameters\n",
    "tree_smoteen_gradient_boost = GradientBoostingClassifier(\n",
    "    n_estimators=150,       # Number of boosting stages\n",
    "    learning_rate=0.1,      # Step size shrinking\n",
    "    max_depth=3,            # Maximum depth of the tree\n",
    "    subsample=0.8,          # Fraction of samples used for fitting \n",
    "                            # each base learner\n",
    "    random_state=42         # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pipeline with SMOTEEN and Gradient Boosting\n",
    "pipeline_smoteen_gradient_boost = Pipeline([\n",
    "    ('smoteen', smoteen), \n",
    "    ('classifier', tree_smoteen_gradient_boost)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the pipeline\n",
    "# Predict probabilities for ROC AUC and threshold adjustment\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Adjust threshold to 0.9\n",
    "threshold = 0.9  # Adjust this value to tune precision/recall tradeoff\n",
    "y_pred_estimators150 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy = accuracy_score(y_test, y_pred_estimators150)\n",
    "precision = precision_score(y_test, y_pred_estimators150 , pos_label=1)\n",
    "recall = recall_score(y_test, y_pred_estimators150 , pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred_estimators150 , pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  \n",
    "\n",
    "# Print the evaluation maetrics\n",
    "print(\"Decision Tree with Gradient Boosting and SMOTEEN Metrics (n_estimators = 150):\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report (n_estimators = 150):\")\n",
    "print(classification_report(y_test, y_pred_estimators150))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix (n_estimators = 150):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_estimators150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77924ebb-e54b-4223-8832-4e29fad5c98e",
   "metadata": {},
   "source": [
    "## Hyperparameter Evaluation: n_estimators\n",
    "\n",
    "* n_estimators = 50\n",
    "\n",
    "Changing the n_estimators to 50 resulted in a Precision value of 0.88 and a fairly dramatic drop in True Positives from our current best model of 208 to 112 and the True Negatives cut in half from 33 to 16. This shows that the model has a high threshold for only choosing stocks that have a very high probability of beating their estimated earnings.\n",
    "\n",
    "* n_estimators = 150\n",
    "\n",
    "Changing the n_estimators to 150 resulted in a Precision value of 0.84, which is a slight step down from our current best model. The True Positives to 258 from the current best model of 208. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95591e2-af78-4881-b6f2-c32b0b6bff04",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "After creating the a baseline model, we tuned it by applying techniques for data augmentation, preprocessing, and hyperparameter modification. Below is a description of our baseline model and final model. \n",
    "\n",
    "### Base Model\n",
    "\n",
    "#### _Model Type_\n",
    "* Decision Tree\n",
    "\n",
    "### Final Model:\n",
    "\n",
    "#### _Model Type_\n",
    "* Decision Tree\n",
    "\n",
    "#### _Tuning_\n",
    "* SMOTEEN\n",
    "* Gradient Boosting\n",
    "* Threshold = 0.9\n",
    "* Subsample = 0.8\n",
    "* n_estimators = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631ca75-2281-4654-9290-0c9a6329a6ff",
   "metadata": {},
   "source": [
    "# Testing Dataset vs. Training Dataset Metrics\n",
    "We are now going to compare and evaluate the metrics of the final model on the testing dataset and the training dataset. The goal of this is not only to see the results of our model for investor recommendations, but to see if there are any major changes in the results once the model is run on the training dataset and testing dataset separately. If the model performs way better on the training set than the test set, this indicates overfitting and the model may be memorizing training data instead of generalizing. If the mode performs poorly on both the training and testing datasets, it indicates underfitting or an oversimplified model. Idealy, performance on both the training dataset and testing dataset should be relativley similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "408caf0a-04f9-441b-be0c-329e8d930cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 0.49\n",
      "Precision: 0.86\n",
      "Recall: 0.20\n",
      "F1 Score: 0.33\n",
      "ROC AUC: 0.74\n",
      "\n",
      "Confusion Matrix (Training Set):\n",
      " [[3521  188]\n",
      " [4668 1194]]\n",
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.47\n",
      "Precision: 0.83\n",
      "Recall: 0.18\n",
      "F1 Score: 0.29\n",
      "ROC AUC: 0.67\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      " [[ 875   52]\n",
      " [1208  258]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline_smoteen_gradient_boost.fit(x_train, y_train)\n",
    "\n",
    "# Predictions and evaluation on the training set\n",
    "y_train_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_train)[:, 1]\n",
    "y_train_pred = (y_train_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance on the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, pos_label=1)\n",
    "train_recall = recall_score(y_train, y_train_pred, pos_label=1)\n",
    "train_f1 = f1_score(y_train, y_train_pred, pos_label=1)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Precision: {train_precision:.2f}\")\n",
    "print(f\"Recall: {train_recall:.2f}\")\n",
    "print(f\"F1 Score: {train_f1:.2f}\")\n",
    "print(f\"ROC AUC: {train_roc_auc:.2f}\")\n",
    "print()\n",
    "print(\"Confusion Matrix (Training Set):\\n\", train_conf_matrix)\n",
    "print()\n",
    "\n",
    "# Predictions and evaluation on the test set\n",
    "y_pred_proba = pipeline_smoteen_gradient_boost.predict_proba(x_test)[:, 1]\n",
    "y_pred_estimators50 = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_estimators50)\n",
    "test_precision = precision_score(y_test, y_pred_estimators50, pos_label=1)\n",
    "test_recall = recall_score(y_test, y_pred_estimators50, pos_label=1)\n",
    "test_f1 = f1_score(y_test, y_pred_estimators50, pos_label=1)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Precision: {test_precision:.2f}\")\n",
    "print(f\"Recall: {test_recall:.2f}\")\n",
    "print(f\"F1 Score: {test_f1:.2f}\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.2f}\")\n",
    "print()\n",
    "\n",
    "# Display the confusion matrix for the test set\n",
    "\n",
    "print(\"Confusion Matrix (Test Set):\\n\", confusion_matrix(\n",
    "    y_test, y_pred_estimators50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d6eee-1a25-449c-bec6-c15b886e6fe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Metric Evaluation: Training Dataset vs. Testing Dataset\n",
    "Upon running our model separately on the training dataset and testing dataset, we can see that the metrics are relativley similar, which means there is a low chance that the model is overfitting or underfitting the data. Below are the results and the % change from the training dataset to the testing dataset\n",
    "\n",
    "| Metrics:     |_Training Dataset_    |    _Testing Dataset_  |    _% Change_ |\n",
    "|--------------|----------------------|-----------------------|---------------|\n",
    "| * Accuracy   |      0.44            |            0.43       |         -2.27%   |\n",
    "| * Precision  |      0.89            |            0.88       |         -1.12%   |\n",
    "| * Recall     |      0.09            |            0.08       |         -11.11%  |\n",
    "| * F1 Score   |      0.17            |            0.14       |         -17.65%  |\n",
    "| * ROC AUC    |      0.71            |            0.67       |         -5.63    |\n",
    "\n",
    "As you can see, the % change in the Precision values (our most important metric) differs between the training dataset and testing dataset by 1.12%. This is a great result because it means the performance on both datasets is relatively similar. The Recall and F1 Score differ by much bigger values, 11.11% and 17.65% respectivley. Although these are significant differences, our model was built around maximizing the Precision value, so we do not need to worry about the variation in Recall values and F1 Scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75845ad9-8c7a-455b-a898-4e35f014c8c8",
   "metadata": {},
   "source": [
    "## Full Dataset\n",
    "Below is the output metrics of the full dataset (training dataset + testing dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94e3ab2e-c613-4c5d-8160-65b0795e4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Results:\n",
      "Accuracy: 0.49\n",
      "Precision: 0.86\n",
      "Recall: 0.20\n",
      "F1 Score: 0.32\n",
      "ROC AUC: 0.73\n",
      "\n",
      "Classification Report on Full Dataset using Final Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.95      0.59      4636\n",
      "           1       0.86      0.20      0.32      7328\n",
      "\n",
      "    accuracy                           0.49     11964\n",
      "   macro avg       0.64      0.57      0.46     11964\n",
      "weighted avg       0.69      0.49      0.43     11964\n",
      "\n",
      "Confusion Matrix on Full Dataset using Final Model:\n",
      " [[4396  240]\n",
      " [5876 1452]]\n"
     ]
    }
   ],
   "source": [
    "# Model used on full dataset\n",
    "# Combine the training and testing datasets\n",
    "x_full = pd.concat([x_train, x_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "# Predict probabilities for the entire dataset\n",
    "y_full_proba = pipeline_smoteen_gradient_boost.predict_proba(x_full)[:, 1]\n",
    "\n",
    "# Adjust the threshold for predictions\n",
    "threshold = 0.9  # Adjust this value as needed\n",
    "y_full_pred_final_model = (y_full_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model's performance on the entire dataset\n",
    "accuracy_full = accuracy_score(y_full, y_full_pred_final_model)\n",
    "precision_full = precision_score(y_full, y_full_pred_final_model, pos_label=1)\n",
    "recall_full = recall_score(y_full, y_full_pred_final_model, pos_label=1)\n",
    "f1_full = f1_score(y_full, y_full_pred_final_model, pos_label=1)\n",
    "roc_auc_full = roc_auc_score(y_full, y_full_proba)  \n",
    "# Print evaluation metrics for the entire dataset\n",
    "print(\"Final Model Results:\")\n",
    "print(f\"Accuracy: {accuracy_full:.2f}\")\n",
    "print(f\"Precision: {precision_full:.2f}\")\n",
    "print(f\"Recall: {recall_full:.2f}\")\n",
    "print(f\"F1 Score: {f1_full:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc_full:.2f}\")\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report on Full Dataset using Final Model:\")\n",
    "print(classification_report(y_full, y_full_pred_final_model))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix on Full Dataset using Final Model:\\n\"\n",
    "      , confusion_matrix(y_full, y_full_pred_final_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d240c-8218-4cc7-8ce0-24b1f8d95ec3",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Out of the 22 parameters used in this model, we want to see which features are contributing the most to the model's predictions. Below we run code to find the relative contribution of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da092dc5-3baf-4460-bbaa-a5adc07bc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Feature Importances:\n",
      "                       Feature  Importance  Percentage\n",
      "5   Earnings Per Share Forward    0.188414   18.841426\n",
      "6             Return on Equity    0.124586   12.458632\n",
      "3          Price to Book Ratio    0.068016    6.801605\n",
      "8               Free Cash Flow    0.065946    6.594593\n",
      "9               Revenue Growth    0.060459    6.045852\n",
      "0                   Market Cap    0.056005    5.600493\n",
      "4               Dividend Yield    0.047468    4.746797\n",
      "12                Gross Margin    0.045795    4.579521\n",
      "16            Return on Assets    0.039407    3.940707\n",
      "20        Book Value Per Share    0.039394    3.939386\n",
      "1           Trailing P/E Ratio    0.033917    3.391659\n",
      "15                 Quick Ratio    0.033253    3.325307\n",
      "2            Forward P/E Ratio    0.031384    3.138401\n",
      "17            Enterprise Value    0.031102    3.110185\n",
      "7         Debt to Equity Ratio    0.030910    3.091011\n",
      "10           Beta (Volatility)    0.024008    2.400769\n",
      "18  Enterprise Value to EBITDA    0.021966    2.196585\n",
      "11            Operating Margin    0.021661    2.166056\n",
      "13        Price to Sales Ratio    0.018292    1.829229\n",
      "14               Current Ratio    0.018018    1.801783\n",
      "19                   PEG Ratio    0.000000    0.000000\n",
      "21               Pays Dividend    0.000000    0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Access feature importances from the trained Gradient Boosting model\n",
    "feature_importances = pipeline_smoteen_gradient_boost.named_steps[\n",
    "    'classifier'].feature_importances_\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': x_full.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Add percentage contribution for better interpretation\n",
    "importances_df['Percentage'] = (importances_df['Importance'] / \n",
    "                                importances_df['Importance'].sum()) * 100\n",
    "\n",
    "# Display top features\n",
    "print(\"Top Feature Importances:\")\n",
    "print(importances_df)  # Adjust the number of top features to display\n",
    "\n",
    "# Show only top 5 features on the plot\n",
    "top_5_features = importances_df.head(5)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.barh(top_5_features['Feature'], top_5_features['Percentage']\n",
    "                , color='darkgreen')\n",
    "plt.xlabel('Feature Importance (%)', fontsize=20)\n",
    "plt.ylabel('Features', fontsize=20)\n",
    "plt.title('Feature Importance for Final Model', fontsize=20)\n",
    "\n",
    "# Adjust tick label font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Add \"%\" symbol to x-axis values\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.1f}%'))\n",
    "\n",
    "# Add percentage values to the right of the bars\n",
    "for bar, percentage in zip(bars, top_5_features['Percentage']):\n",
    "    plt.text(\n",
    "        bar.get_width() + 0.2,  # Position to the right of the bar\n",
    "        bar.get_y() + bar.get_height() / 2,  # Vertically centered on the bar\n",
    "        f'{percentage:.1f}%',  # Text to display\n",
    "        va='center',  # Align text vertically\n",
    "        ha='left',  # Align text horizontally\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "plt.xlim(0, 25)  # Set the x-axis range from 0 to 30\n",
    "\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4956a-ca23-426c-91e0-66fb6e00464d",
   "metadata": {},
   "source": [
    "## Feature Performance Evaluation\n",
    "The feature contributing most to the features conbtributions is Earnings Per Share Forward at 18.8%%. Earnings Per Share Foward is an estimate of a company's future earnings per share for the next fiscal quarter or year, which is forecasted by financial analysts, investment firms, and research departments. Even though this is predicting what the stock's earnings report will be for the next quarter, it is not an example of data leakage because this is publicly available information and is only an estimate of the future earnings per share value. The next highest contributing feature is Return on Equity at 12.5%%. Return on Equity measures a company's profitability relative to its shareholders' equity. It's indicating how effectivley a companyis using the capital invested by its' shareholders to generate profits. \n",
    "\n",
    "The rest of the features contribute less than 6% each to the model's prediction, with the exception of PEG Ratio and Dividend Payment, which contribute 0%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad1a59c-f6a8-4935-b9bd-d69642b918f6",
   "metadata": {},
   "source": [
    "## Stocks with Highest Probability of Beating Earnings\n",
    "We're going to make a list of the top 25 stocks with the highest probability of beating their next estimated EPS, as predicted by the model. To do this, we'll use the y_full_proba, which is a variable we created in our model that retreives the probability that each stock will belong to class 1 (beating their estimated EPS). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e84b2aaa-2821-4ffe-aab7-62cc091d3d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 Stocks with the Highest Probability of Beating Earnings:\n",
      "     Symbol  Probability\n",
      "1996    NVO     0.988774\n",
      "1776   META     0.986799\n",
      "1849    MRK     0.986706\n",
      "10     ABBV     0.985300\n",
      "1863   MSFT     0.985024\n",
      "1662    LMT     0.984236\n",
      "1458   INTU     0.984110\n",
      "2656    SYK     0.983663\n",
      "1721     MA     0.982952\n",
      "731     CRM     0.982934\n",
      "2290   QCOM     0.982636\n",
      "2872      V     0.982531\n",
      "1214   GILD     0.982119\n",
      "89     AGYS     0.981985\n",
      "2149    PEP     0.981877\n",
      "1525    JNJ     0.981763\n",
      "183    ANET     0.981698\n",
      "2787   TSLA     0.981647\n",
      "50     ADBE     0.981557\n",
      "1932   NFLX     0.980907\n",
      "1393    IBM     0.980716\n",
      "2168    PGR     0.980403\n",
      "1490   ISRG     0.980092\n",
      "2110   PANW     0.979983\n",
      "1187     GE     0.979315\n"
     ]
    }
   ],
   "source": [
    "# Add probabilities and stock identifiers to a dataframe for \n",
    "# the top 25 highest probability stocks\n",
    "# Create a new DataFrame in order to keep the x_full DataFrame \n",
    "x_full_probability = x_full.copy()\n",
    "\n",
    "# Add a column to the DataFrame called 'Probability' containing \n",
    "# the y_full_proba values calculated by our model \n",
    "x_full_probability['Probability'] = y_full_proba\n",
    "\n",
    "# Add the 'Symbol' column back into our Dataframe so we can see it\n",
    "x_full_probability['Symbol'] = df_merged_stocks_data_scaled['Symbol']  \n",
    "# Create a DataFrame showing probabilities sorted (descending), \n",
    "# stocks grouped by 'Symbol' as we still have one row for each of the \n",
    "# four quarterly estimated EPS  reports per stock, and extract the top 25\n",
    "top_25_stocks = x_full_probability.groupby('Symbol', as_index=False).agg(\n",
    "    'first').sort_values(by='Probability', ascending=False).head(25)\n",
    "\n",
    "# Display the top 25 stocks\n",
    "print(\"Top 25 Stocks with the Highest Probability of Beating Earnings:\")\n",
    "print(top_25_stocks[['Symbol', 'Probability']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "232204b7-c71e-48dd-950c-00574b8d39bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Your data preparation code remains the same\n",
    "x_full_probability = x_full.copy()\n",
    "x_full_probability['Probability'] = y_full_proba\n",
    "x_full_probability['Symbol'] = df_merged_stocks_data_scaled['Symbol']\n",
    "\n",
    "# Aggregate and sort data for the top 25 stocks\n",
    "top_5_stocks = (\n",
    "    x_full_probability.groupby('Symbol', as_index=False)\n",
    "    .agg({'Probability': 'first'})  # Take the first probability per stock\n",
    "    .sort_values(by='Probability', ascending=False)\n",
    "    .head(5)\n",
    ")\n",
    "\n",
    "# Multiply probabilities by 100 for percentage values\n",
    "top_5_stocks['Probability'] = top_5_stocks['Probability'] * 100\n",
    "\n",
    "# Plotting the top 5 stocks\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(top_5_stocks['Symbol'], top_5_stocks['Probability']\n",
    "                , color='darkgreen')\n",
    "plt.xlabel('Probability of Beating Estimated EPS', fontsize=20)\n",
    "plt.ylabel('Stock Symbol', fontsize=20)\n",
    "plt.title('Top 5 Stocks with the Highest Probability of Beating Estimated EPS'\n",
    "          , fontsize=24)\n",
    "\n",
    "# Adjust tick label font sizes\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "# Add probability values to the right of the bars\n",
    "for bar, probability in zip(bars, top_5_stocks['Probability']):\n",
    "    plt.text(\n",
    "        bar.get_width() + 0.01,  # Position to the right of the bar\n",
    "        bar.get_y() + bar.get_height() / 2,  # Vertically centered on the bar\n",
    "        f'{probability:.2f}%',  # Text to display\n",
    "        va='center',  # Align text vertically\n",
    "        ha='left',  # Align text horizontally\n",
    "        fontsize=20\n",
    "    )\n",
    "\n",
    "# Add \"%\" symbol to x-axis values\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.1f}%'))\n",
    "\n",
    "plt.xlim(98.2, 99)  # Set the x-axis range from 95 to 96\n",
    "\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfbb36-a2a3-412f-bb1b-f53571f61587",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To wrap up this analysis, we'll end by giving an overall summary of the process we took to build our model, the limitations of data collection and model results, potential solutions to those limitations, future actions to improve our model.\n",
    "\n",
    "### Summary\n",
    "* Pull the top 5,000 stocks by market cap from the NASDAQ website (https://www.nasdaq.com/market-activity/stocks/screener) which gave us stock ticker, company name, and current market cap value\n",
    "* Remove any stocks that aren't common shares, such as capital stock, registry shares, and global notes\n",
    "* Import stock valuation parameters and earnings report history from Yahoo Finance for our list of stocks, remove unavailable parameter values, and impute specific values to maintain consistency in  the dataset\n",
    "* Remove certain columns to prevent data leakage and scale the data in preparation for modeling\n",
    "* Analyze metrics we will use to evaluate our model and decide which metric is most important for our business goal (Precision value)\n",
    "* Run the data through two different types of models (Logistic Regression and Decision Tree) and choose which one has the best performance for our specific needs (Decision Tree)\n",
    "* Implement data preprocessing techniques, tune hyperparameters, and compare the results of each modification to the baseline model to see if there was an increase in model performance. If an increase in performance is observed, keep the modification and move on to the next technique. Revise the model until performance improves to a sufficient level\n",
    "* Run the final model on both the training dataset and testing dataset to confirm generalizing (model is not overfit to only work on the training data), run model on full dataset, and create a list of the top 25 stocks with the highest probability of beating their earnings report\n",
    "\n",
    "### Limitations\n",
    "* Data pulled from Yahoo Finance, while free, is limited in terms of real-time data and historical data. The market cap and valuation parameters are not updated in real time, but appear to be updated periodically, possible on a daily or weekly basis, though the exact timeframe is unknown. On top of this, there is a constraint on how much historical data can be retrieved. For example, only the most recent four quarterly earnings reports are available for stocks.\n",
    "* Retrieving the original 24 stock valuation parameters for 5,000 stocks took almost an hour to generate. Future projects may lead to a dramatic increase in the number of parameters desired in order to discover new patterns and correlations in the data, increasing processing time exponentially.\n",
    "* The main method for finding the ideal preprocessing techniques and hyperparameter tunings was trial-and-error. Hyperparameter optimization techniques, like GridSearchCV, reduce the number of models that need to be tested, streamlining the tuning process. Unfortunately, these optimization techniques required more computational resources than my computer could provide, preventing me from utilizing these strategies.\n",
    "* Our target variable is earnings outcome, which is whether the stock beat their estimated earnings per share. A stock beating it's quarterly estimated earnings per share is a good indicator that the company is doing well fundamentally and has a much higher probability of increasing its' price, as opposed to a company that matched or missed its' estimated earnings per share. However, a company beating its' estimated earnings per share is not a guarantee that the stock will move up, especially in the short term. There are times where a company will greatly exceed its' estimated earnings per share, but the price will fall in the days following the announcement. This that there are other factors besdies beating its' estimated earnings per share that go into an increase in stock price. \n",
    "\n",
    "### Potential Solutions to these Limitations\n",
    "* Financial data providers, such as Bloomberg Terminal and Alpha Vantage, provide APIs for accessing historical and real-time stock market data. These resources would provide us with accurate real-time data to ensure our model is up-to-date, along with extensive historical data spanning multiple years, rather than being limited to just a year or two. These services are expensive and cost anywhere from hundreds to thousands of dollars per month and have rate limits, which means that only a certain amount of data is able to be pulled every hour.\n",
    "* There are a few options to reduce processing time for large dataset analysis and computationally intensive modeling. One option is to install one or multiple GPU (Graphics Processing Unit) units, which can significantly increase computational capability for tasks that involve large amounts of data and machine learning models. Another option is to invest in infrastructure, like powerful servers and GPUs, and rent out space in a data center. These data centers provide cooling, security, maintenance, and monitoring, reducing costs associated with real estate, power, cooling, and personnel. One more option is use Cloud Hosting, which is renting servers and GPUs from data centers or cloud providers, like Amazon Web Services (AWS), Google Cloud, or Microsoft Azure. This is the most cost effective in the short term, as we don't need to purchase or manage the hardware ourself. We pay for the computational power and resources used, and the provider is responsible for maintaining the infrastructure.\n",
    "* Factors other than a stock beating its' estimated earnings per share may be a better indicator for a stock increasing in price, such as other types of valuation parameters or technical analysis indicators. We may also find that stocks that beat their estimated earnings per share may, on average, experience a percentage increase in price that is greater than the percentage decline when they miss estimates, leading to a long-term upward trend in average price. This would need to be calculated and proven using historical earnings reports and price data. \n",
    "\n",
    "### Future Actions for Improvement\n",
    "* With the addition of Financial data providers, like Bloomberg Terminal, more stock valuation parameters and ratios will be available, which can be added to the model in order to see if any of them have a significant predictive power.\n",
    "* Technical analysis (TA) is a method of evaluating future stock price movement using historical data, primarily price and volume. Unlike fundamental analysis, which focuses on a company's financial performance and intrinsic value (this project is based on fundamental analysis), TA is concerned with identifying patterns and trends in the data. TA often uses candlestick charts and uses mathhematical calculations based on price and volume, like Moving Averages (average price over a set period of time, i.e. 5 day MA, 50 day MA etc.), Relative Strength Index (measures the speed and chance of price movements to determine overbought or oversold conditions), Bollinger Bands (indicates price volatility by plotting two standard deviationos away from a moving average), and many more. Since these indicators and patterns are used by stock/commodity traders to determine future price movements, we can try implementing these tools to our model to see if they enhance predictive power.\n",
    "* In this model, we focused on logistic regression and decision trees. However, other machine learning algorithms and statistical approaches, such as Support Vector Machines (SVM), Neural Networks, and Random Forest. Most of these require greater computational power than the approach taken in this project, but may lead to more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9640a-8078-4ba5-9cf8-9d0ffd244a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
